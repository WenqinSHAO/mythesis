%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

As transit price continues to drop, mulithoming has now become a common practice among many medium and even small size networks. Yet, improving the transmission performance over multiple Internet paths remains challenging.
%Yet, how to improve the transmission performance through wise employment of multiple Internet paths remains challenging. 
One major difficulty comes from the current Internet routing protocol \acf{BGP}.
It is not performance-aware in propagating and choosing routes. 
On top of that, \ac{BGP} is not going to obsolete shortly.

To bypass the limitations of \ac{BGP}, some previous studies and industrial solutions suggest regular measurement of transmission performance over all available paths.
Then, the best routes are chosen for each destination considering not alone policies but as well measurements. That is the main idea of measurement-based \acf{TE}.
In transferring this idea into designs/systems that can cope with real network requirements, plenty of  issues are still left open.

First, measurement-based TE has to deal with the huge number of potential destinations.
This heavy measurement load is further multiplied by the number of available paths/providers.
Instead of covering the entire address space, it is more resource efficient to focus on several important destinations.
To verify the feasibility of that intuition, we studied working traffic traces from real networks.
The results showcased that most traffic is indeed concentrated on a small fraction of destinations.
Based on these findings, we devised simple methods to predict those `heavy-hitter' destinations.

Second, measurement-based TE requires insightful measurement interpretation.
In this work, we mainly cared about round-trip latency on Internet paths.
We first identified and diagnosed several data quality issues that were previously unattended.
Guidelines to mitigate their impacts were discussed.
Further, we tried to cluster latency time series with similar characters, e.g. overall variation level, a particular shape at a given moment.

We encountered difficulties in meaningfully clustering latency measurements. 
These difficulties led us to the detection of moments of significant changes for individual latency time series.
Moments of performance change can be regarded as a compact data representation of latency time series. They therefore have the potential to facilitate the grouping/clustering operation.
Ultimately, these moments are when route re-selection is potentially needed for the measured destinations.
Because otherwise traffic toward these destinations might suffer from avoidable performance degradation.
To that end, we applied \textit{changepoint analysis} methods to latency time series.
We devised an evaluation framework to quantify the robustness and sensitivity of diverse detection methods.
With the open-sourced evaluation method, we aimed at encouraging as well further efforts on methodological improvements.

Last but not the least, we tried to infer the network locations that are responsible for significant latency changes. This visibility allows performance-aware route selection for certain destinations that can not be measured directly.
When paths toward these destinations traverse change causes, we reasonably assume similar performance changes on these paths as well.
We since developed a series of inference procedures to attribute the cause of latency changes to \acf{AS} or inter-AS links.
Change detection methods previously studied were employed to first detect performance changes and then to group paths that underwent a same performance change.
To better illustrate the inference process and the identified causes for latency change, we built two interactive visualization tools to plot the results on a topology graph.

In this dissertation, we tackled some of the most pronounced challenges in measurement-based TE for interdomain routing. Contributions are brought to measurement scalability, interpretation of performance data and visibility on causes of performance changes. 
\vfill

\newpage

\begin{otherlanguage}{french}
\pdfbookmark[1]{Résumé}{Résumé}
\chapter*{Résumé}
Avec la baisse du prix de transit, multihoming a maintenant devenu une pratique courante parmi les réseaux de moyenne même petite taille.
Toutefois, il reste difficile de réellement améliorer la performance de transmission via ces multiple chemin désormais disponibles.
Une des difficultés est d’originaire du protocole de routage employé dans ce contexte : \acf{BGP}.
Le protocole ne prend pas en compte les éléments de performance lors de la sélection et la propagation des routes.
De plus, ce protocole va probablement continuer à dominer les routages d’Internet.

Pour pouvoir contourner les contraints du \ac{BGP}, des études dans le passé et des solutions industrielles suggèrent de mesurer régulièrement les multiples chemin Internet.
Puis, la meilleure route à chaque destination est sélectionnée selon les données de ces mesures. C’est ce que nous appelons l’ingénierie du trafic (TE) alimenté par la mesure.
En réalisant cette idée et satisfaisant les requis des vrais réseaux, pleine de problèmes sont laissés ouverts.

D’abord, un system comme tel doit pouvoir gérer énorme de destinations.
Cela pesse lourdement sur la fonctionnalité de mesure.
En plus, cette charge est multipliée par le nombre de chemins disponibles.
Au lieu de couvrir la totalité des destinations, il est clairement plus sage de se focaliser sur certains unes les plus importantes.
Afin de vérifier que ce soit faisable, nous avons étudié des vrais trafics sur les vrais réseaux à profils variés.
Le résultat montre qu’effectivement une grande partie de trafic se concentre sur une petite collection de destinations.
De plus, les trafics associés aux ces destinations sont relativement plus facile à prédire que le reste.
S’appuyant sur ces découverts, nous avons identifié des moyens simples mais efficaces à capter ces destinations d’importance.

Deuxièmement, les données récoltées par le system de mesure restent à être interpréter.
Dans cette thèse, nous nous occupons principalement la latence d’aller-retour comme l’indicateur de performance d’un chemin.
Nous avons commencé par identifier et analyser certains problèmes liés à la qualité de données.
Nous avons également discuté comment atténuer ces impacts.
En outre, nous avons essayé de grouper ensemble des séries temporelles de latence qui partage des traits similaires, par exemple vécus un changement au même moment.

En donnant des sens pratiques aux groups résulté, nous avons rencontré des difficultés.
Ils nous ont dirigé vers la détection de changement pour des séries temporelles de latence.
Les moments de changement significatif se peuvent être regardés comme un représentation compacte pour les données de performance. 
Ils nous facilitent ainsi l’opération de regroupage plus tard. 
Finalement, ces changements servent également comment déclencheur à la réévaluation des routes sélectionnées.
Car quand un changement de performance est survenu sur l’un des chemins mesurés, il indique soit une dégradation potentielle soit des espaces à l’amélioration. 
S’en rendant compte, nous avons mis en pratique des méthodes de \textit{changepoint analysis} sur des séries temporelles de latence.
Nous avons même conçu un mécanisme d’évaluation de la qualité de détection pour données de type latence Internet.
Les implémentations de cet outils et données labélisées sont rendu publique, dans l’objectif d’encourager les efforts à venir sur la méthodologie de détection.

Finalement, nous avons essayé d’inférer les endroits dans l’Internet qui sont susceptibles d’être la cause des changements de performance détectés.
Cette visibilité permet de réagir aux accidents pour certain destinations que nous n’arrivions pas à mesurer directement.
Quand certains chemins vers ces destinations traversent une cause de changement, il est probable que ces chemins non mesurés ont vécu le même changement que les autres mesurés.
Basant sur cette hypothèse, nous avons développé une sérié de logique qui attribue la cause de chaque changement de performance à un réseau sur le chemin ou un bout de lien entre deux réseaux.
Les méthodes de changpoint analysis étudiées plutôt nous aident d’abord à identifier les changements de performance sur chaque chemin mesuré, et puis à regrouper les chemins par les changements qu’ils ont vécu.
Pour mieux illustrer le processus et les résultats de l’inférence, nous avons développé des outils interactifs projetant les outputs de chaque étape sur une graphe de topologie.

Dans cette thèse, nous avons entrepris des défis les plus remarqués concernant l’ingénierie du trafic alimenté par la mesure dans routage Internet. Nous avons apporté des contributions sur la scalabilité, l’interprétation des données et la visibilité sur la cause de variation de performance.

\end{otherlanguage}


\begin{otherlanguage}{french}
\pdfbookmark[1]{Condensé du Manuscrit}{Condensé du Manuscrit}
\chapter*{Condensé du Manuscrit}
\section*{Introduction}
Internet est une collection de réseaux gérés individuellement.
Son système de gestion et de routage distribué lui permet de se développer rapidement.
Cependant, la distribution du trafic sous-optimale à partir d'une vue globale est d'originaire également de ce comportement distributé.
Ce problème se manifeste souvent par des congestion lorsqu'il existe encore de la capacité disponible.
De nombreux efforts ont donc été consacrés à une meilleure performance de la transmission, en allégeant ou en évitant la congestion.

La congestion se produit sur un chemin Internet partagé par plusieurs flux lorsque la demande totale dépasse la capacité de liaison.
En évitant la concurrence vicieuse qui finit par bloquer tous les flux, le mécanisme de contrôle de la congestion de bout en bout joue un rôle important. Il améliore les performances de transmission de manière distribuée.
Il vise à 1) utiliser pleinement la bande passante tout en 2) introduisant un minimum de retard de transmission supplémentaire (longueur de file d'attente courte) et 3) assurant un partage équitable des ressources ~\cite{Jacobson1988, mathis1997macroscopic, Cardwell2016}.

Les performances de transmission peuvent être encore améliorées avec une capacité de liaison suffisamment importante pour satisfaire la demande de tous les flux. À cette fin, il est nécessaire de dimensionner régulièrement le réseau en fonction de la croissance des demandes de trafic ~\cite {pioro2004routing}.
Pourtant, la construction d'infrastructures ne suffit pas. Premièrement, le déploiement du réseau se déroule sur une période beaucoup plus longue que les fluctuations du trafic. Avant que la capacité supplémentaire ne soit déployée, certains liens peuvent devenir saturés alors que d'autres restent presque inactifs en raison des changements dans la demande de trafic. Deuxièmement, le surdimensionnement est coûteux, étant donné que les technologies futures réduiront considérablement le coût par unité de bande passante.

Par conséquent, des schémas de routage réactifs et flexibles sont nécessaires, complémentaires au dimensionnement du réseau.
Ils maximisent la capacité utile réelle.
Au sein d'un réseau (intradomaine), l'administrateur peut en premier lieu estimer/modéliser la matrice de trafic qui traverse son réseau. 
Ensuite, chaque flux peut être divisé en plusieurs chemins pour s'adapter au mieux à la capacité disponible ~\cite {Xu2011, Jain2013}.
Parmi différents réseaux (interdomaines), la marge d'amélioration des performances provient principalement de plusieurs chemins Internet entre les réseaux source et ceux de destination.
C'est parce que la capacité de bout en bout est potentiellement élargie avec des chemins Internet plus riches.
Une telle diversité de chemins peut déjà être obtenue via multihoming sous current \acf{BGP}. Avec le multihoming, un réseau achète l'accès au reste de l'Internet via plusieurs fournisseurs.
De nombreuses autres propositions encouragent également la propagation de plusieurs chemins Internet, pour ne citer que quelques-un : BGP add-path~\cite{addpath}, MIRO~\cite{Xu2006}, NIRA~\ cité{Yang2007}, YAMR~\cite{Ganichev2010 }, Pathlet~\cite{Godfrey09}, IDRD~\cite{Misseri2013}, et etc.
Cependant, dans le routage interdomaine, chaque réseau n'a toujours pas la visibilité en dehors de son propre territoire, par exemple, la capacité d'une liaison distante et la demande de trafic concurrent d'autres réseaux sur ce lien.
Ceci est particulièrement vrai avec \ac{BGP}, le protocole de routage interdomaine de facto qui ne va pas être obsolète prochainement.
Par conséquent, il n'est pas possible pour les réseaux actuels de déterminer quels chemins disponibles offrent les meilleures performances vers une destination donnée.
En d'autres termes, le défi est de savoir comment mieux utiliser la capacité Internet disponible avec un protocole agnostique de performance \ac{BGP}.
Nous entreprenons ce défi dans cette dissertation.

Un moyen simple de rendre la décision de la route sensible aux performances est la mesure. Dans l'ingénierie de leur interconnection avec les autres réseaux, Facebook et Google utilisent des instruments intégrés dans leurs applications pour apprendre les performances de bout en bout sur plusieurs chemins disponibles ~\cite {Yap2017, Schlinker2017}.
Au fur et à mesure que le prix du transit diminue, le multi-homing devient plutôt une pratique courante dans de nombreux réseaux de petite et moyenne taille.
Ces réseaux ont également un besoin immédiat d'amélioration des performances, de sorte que leurs buinesses puissent survivre.

Malgré le besoin concret d'ingénierie du trafic interdomaine basée sur des mesures, de nombreuses questions restent sans réponse ou partiellement traitées.
Un réseau typique peut communiquer régulièrement avec des destinations différentes $\sim$ 100k.
Mesurer continuellement la performance de toutes ces destinations est coûteux et n'est pas nécessaire.
Quelles sont les destinations les plus importantes? Est-ce que ces destinations changent au fil du temps? Comment les identifier?
En outre des mesures de volume, comment les mesures de performance doivent-elles être traitées? Ont-ils besoin de nettoyage?
Si oui, quels sont les problèmes potentiels de qualité des données? Quelles sont les origines de ces problèmes? Comment pouvons-nous mettre en valeur et atténuer leurs impacts sur la sélection des itinéraires?
En outre, afin de réagir dynamiquement aux changements de performance, comment détecter en premier lieu des changements significatifs dans les mesures de performance? Comment le faire sans paramètres codés en dur ou ad hoc? Comment atteindre un niveau de robustesse acceptable?
Enfin, une fois qu'un changement de performance est détecté, comment pouvons-nous en savoir plus sur cet événement du point de vue du réseau? Où cela arrive-t-il? Cela peut-il avoir un impact sur d'autres chemins Internet actuellement utilisés?
Nous cherchons à explorer les réponses aux questions ci-dessus dans cette thèse, afin que la construction d'un système de sélection de routes basé sur des mesures progresse dans ces domaines: extensibilité du system de mesure, interprétation des données de performance et visibilité des causes de changement de performance.


\section*{Le context}
Nous mettons en scène les travaux de cette thèse sous BGP, tout en réalisant pleinement \ac{LISP}, \ac{SDN}, etc. sont des pistes de recherche prometteuses.
C'est parce que BGP sera encore le protocole de routage \textit {de facto} d'Internet dans un avenir prévisible.
Et le déploiement de tout nouveau mécanisme de routage doit être incrémentiel.
Avant la reprise de tout ce qui n'est pas BGP, BGP est ce qu'une majorité d'AS doit vivre avec.
Il y a donc des besoins immédiats d'amélioration.

Nous nous concentrons sur la TE pour trafic sortant dans cette thèse.
Car la TE entrante est intrinsèquement difficile avec le BGP, en raison d'un manque de méthode efficace de guidage du trafic.

Nous ciblons les \acf{AS} stub (potentiellement multi-hébergés).
C'est parce que \acf{CP}, \acf{HP} et \acf{ISP}, étant les principaux types de réseaux parmi les AS stub, sont ceux qui ont le plus besoin de TE.
De plus, la re-sélection de route dynamique dans ces réseaux ne générera pas de problèmes de convergence de routes BGP sur l'Internet.

Enfin, nous supposons que l'amélioration des performances de transmission est aujourd'hui la principale motivation pour la TE sortante.
L'acheminement du trafic sur Internet fait désormais face à moins de contraintes monétaires grâce à la baisse du prix de transit~\cite{transitprice, drpeering} et de la présence des \ac{IXP} de plus en plus dense dans le monde entier~\cite{pchixp}.
En revanche, en vu de la demande pour la diversité géographique et topologique de connexion~\cite {Chiu2015}, un défi de performance reste à relever.

Afin de réaliser réellement ce gain de performance provenant de multiples chemain d'Internet, une sélection de route dynamique basée sur des mesures de performance est requise, c'est-à-dire \textit{TE basé sur des mesures}.
\citet{Akella2008} a montré une demonstration d'un tel system de TE.
Seulement 100 destinations sont émulées dans ce travail.
Ce nombre est beaucoup moins par rapport à l'échelle réelle qu'un AS stub peut faire face sur une base quotidienne.
Dans ce travail, le meilleur itinéraire pour chaque destination est choisi en fonction de \ac{EWMA} sur des mésures de \acf {RTT} dans le passé.
Les résultats montrent que la meilleure performance de transmission sur toutes les destinations est atteinte lorsque la décision d'itinéraire est prise selon uniquement la dernière mesure.
Cependant, compte tenu de la nature bruissante des mesures \ac{RTT}, une telle approche simpliste peut conduire à des changements de chemin extrêmement fréquents.
En outre, traiter Internet comme une boîte noire pour les mesures de latence ne fournit pas une visibilité utile et parfois nécessaire des événements de réseau sous-jacents.
Ces événements de réseau, par ex. les changements de chemin et la congestion sont les causes réelles d'une dégradation significative des performances et ainsi les raisons du changement de route.

Afin de répondre aux préoccupations ci-dessus et de réduire l'écart entre le concept et un système de travail~\cite{b6},
Nous étudions dans cette thèse le volume de trafic, les mesures de latence sur les chemain Internet pour améliorer la scalabilité du system de mésure, l'interprétation des mesures et la visibilité des performances de l'interdomaine TE basé sur les mesures.

Une plate-forme interdomaine TE basée sur la mesure a deux éléments constitutifs essentiels.
Ils sont illustrés en noir sur la figure~\ref{fig: archi}: (i) mesure de la performance des chemins utilisables et (ii) décision d'itinéraire.
La plateforme mesure les performances de bout en bout, plus précisément la latence aller-retour \acf{RTT}, sur toutes les routes disponibles vers un préfixe de destination donné.
Dans chaque préfixe de destination, quelques hôtes avec des ports ouverts, par ex. 80, 443, sont découverts puis utilisés comme destination de mesure.
Une fois alimenté par les mesures de performance, le moteur de décision d'itinéraire choisit pour chaque destination les meilleurs itinéraires à chaque instant et les impose sur les routeurs de frontière BGP.

\section*{La sélection de préfixes les plus importants}

Un réseau client ayant besoin de \acf{TE} interdomain est souvent de type \acf{ISP}, \acf{HP}, \acf{CP}.
Il envoie du trafic vers un large éventail de destinations, en général entre 10k à 100k de prefixes BGP.
Le sous-système de mesure et de décision de route illustré sur la figure~\ref{fig: archi} fait donc face à un défi qui est de suivre et d'optimiser en temps réel les performances de transmission vers toutes ces destinations.
Cependant, il est bien connu que la plupart du volume du trafic est généralement concentré sur une petite partie des préfixes BGP~\cite {Fang1999, Feamster2003, Papagiannaki2005, Sarrar2012}.
Il est donc possible et raisonnable de se concentrer uniquement sur les préfixes de destination les plus importants.

% \ marginpar {la proposition}
A cette fin, il faut prévoir quels préfixes correspondront aux volumes de trafic les plus importants dans un proche avenir.
Deux blocs fonctionnels supplémentaires sont ainsi ajoutés à la conception du système dans la figure~\ref {fig: archi}): (iii) la collecte de statistiques sur le volume de trafic; (iv) la sélection de préfixe, qui identifie parmi l'ensemble des destinations celles les plus importantes (c'est-à-dire ceux ayant le volume le plus élevé dans un avenir prévisible) et communique l'ensemble de préfixes sélectionné aux sous-system de mesure et d'itinéraire.

% \ marginpar {challenges}
Deux raisons nous obligent à \textit{prédictivement} sélectionner des préfixes de volume important et concevoir des mécanismes spécifiques pour cette tâche.
Tout d'abord, le volume de trafic par préfixe évolue avec le temps, de même que l'ensemble des préfixes représentant un volume de trafic important.
Walleriche et al.~\cite{Wallerich2006} ont montré que le classement de la bande passante des flux peut changer radicalement d'un moment à l'autre.
Afin de maintenir un ensemble de préfixes d'importance, il faut donc prévoir à plusieurs reprises le volume de trafic pour chaque préfixe.
À notre connaissance, aucune étude n'a fait l'objet d'une enquête approfondie sur l'évolution dans le temps du volume de trafic associé aux préfixes BGP.

Deuxièmement, en prévoyant le volume de trafic pour chaque préfixe individuel, des méthodes plus efficaces sont nécessaires.
Les modèles bien établis \acf{TSF} et \acf{ANN} ont déjà été utilisés dans la prédiction du trafic~\cite{Papagiannaki2005, Cortez2006, Otoshi2013}.
Ces travaux ciblaient le trafic inter-acf {PoP} hautement agrégé pour les tâches hors ligne, telles que le dimensionnement de réseau.
Ces modèles sont non seulement lourds en termes de calcul, mais ils nécessitent également un pré-traitement des données et un réglage des paramètres d'une manière trace par trace. 
Ces coûts généraux rendent ces méthodes moins applicables dans le contexte de l'inter-domaine TE qui implique jusqu'à 100k préfixes. Par conséquent, des méthodes de prédiction moins complexes sont nécessaires.

Nous avons analysé dans cette partie les traces du trafic réel provenant de neuf réseaux différents situés dans cinq pays pour comprendre la distribution du volume de trafic associé aux préfixes BGP, ainsi que sa variation dans le temps.
Nous avons observé que les préfixes les plus importants (représentant le plus grand volume sur une semaine) sont généralement stables dans le temps, avec de légères variations horaires autour de leur volume moyen en heures.
Sur la base de cette observation, nous avons proposé trois simples
% et resource-economic% GgX: Comment une métrique peut-elle demander des ressources? Son calcul fait mais pas la métrique tiself
métriques (également faciles à calculer) pour sélectionner de manière proactive les préfixes ayant un volume de trafic prévisible important.
Nous avons démontré que les métriques que nous avons proposées conduisent à une meilleure couverture des volumes par rapport aux solutions existantes.
De plus, nous avons évalué les performances de transmission pour les préfixes de destination sélectionnés en utilisant plusieurs fournisseurs de transit.
Nous avons également simulé un algorithme de décision d'itinéraire dynamique.
Les résultats ont montré que même avec un mécanisme assez basique, la performance RTT globale pourrait être améliorée de 20\% par rapport au meilleur fournisseur de transit disponible dans certains réseaux étudiés.

\section{La qaulité des mesures}

À partir d'ici, notre étude se concentre sur les mesures de latence et de trajectoires.
Ces mesures sont disponibles sur les platesformes TE chez les clients, de même que les données de volume étudiées dans le chapitre~\ref{sec: pref_selec}.
Cependant, dans un souci de reproductibilité, nous avons décidé de passer aux mesures effectuées par RIPE Atlas, une plateforme de mesure mondiale offrant un accès ouvert aux données. 

\subsection{La complétude des données}

En plus de la reproductibilité, la qualité des données est un autre aspect clé pour les recherches en métrologie.
Grâce à des études antérieures~\cite{Holterbach2015a, Bajpai2015}, il est maintenant connu que en case de RIPE Atlas, la charge a des impacts évidents sur la précision et l'ordonnancement des mesures.
Nous nous concentrons sur la complétude des données, un autre aspect de la qualité des mesures qui a reçu moins d'attention jusqu'ici. 
Des mesures manquantes peuvent entraîner diverses conséquences indésirables.
En dehors de l'élargissement de l'intervalle de confiance de l'inférence~\cite{Fontugne2016}, 
il nécessite en général des adaptations méthodologiques, par ex. dans l'analyse spectrale~\cite{Babu2010, Luckie2014, shao2016}, 
sinon l'estimation serait biaisée~\cite {Baraldi2010}.
% Il est donc important de s'interroger sur la nature des mesures manquantes.

Une raison évidente de l'absence de données est que la sonde RIPE Atlas ne fonctionne pas (ou pas correctement), par ex. éteinte~\cite{schedule}.
Tant qu'une sonde est alimentée, elle essaie de maintenir une connexion à un contrôleur pour soumettre les mesures et recevoir les allocations des tâches comme indiqué sur la figure~\ref{fig: ripe_atlas_archi}.
Par conséquent, l'activité de connexion de la sonde fournit une bonne indication de la disponibilité de la sonde et est utilisée dans les investigations menées par RIPE sur la stabilité du système d'exploitation de la sonde~\cite{1look, 2look, 3look}.

Afin de déduire l'existence possible d'autres causes, nous avons comparé les horodatages de mesure avec les moments sonde se connecte et se déconnecte du système de contrôleur d'Atlas.
Si les mesures manquantes coïncident avec la déconnexion de la sonde, il y a de fortes chances que la raison de cette manque est que la sonde soit dysfonctionnelle, par ex. éteinte.
Cependant, si les mesures sont perdues alors que la sonde est bien connectée, il faut s'attendre à quelque chose d'anormal, au-delà du problème connu du système d'exploitation de la sonde.

Dans notre analyse couvrant un grand nombre de sondes sur un mois, seulement $60\%$ des sondes v3 Atlas ont des mesures complètes. 
D'environ $1/3$ des segments de manques semblent étroitement liés à la période déconnectée. 
Le problème de stabilité du système d'exploitation de la sonde pourrait avoir contribué à de tels manques, 
comme le suggère la distribution à queue lourde de la longueur des segments manques.

Cependant, $2/3$ des segments de manques restants se sont produits pendant que les sondes sont connectées.
La moitié d'entre eux ne durent pas plus de 2 datapoint et sont donc susceptibles d'être causés par des problèmes d'ordonnancement. 
Cependant, environ $25\%$ de cette catégorie dure longtemps ($\geq 1h$).

Nous avons signalé la découverte à l'équipe d'ingénierie de RIPE avec un cas spécifique qu'ils pourraient examiner.
La dernière réponse de l'équipe RIPE a confirmé que la cas que nous avons cité dans le rapport avait des problèmes de synchronisation de l'heure. 
Pour aider à faire avancer l'enquête, nous avons partagé avec l'équipe RIPE tous les segments de manque de données de longue durée que nous avons identifiés. 
Ces échanges peuvent être trouvés sur le forum RIPE Atlas à \url{https://www.ripe.net/participate/mail/forum/ripe-atlas}, avec le titre ``Actual measurement interval much larger than planned''.

Bien que le résultat final ne soit pas concluant ni révélateur en termes de mécanisme sous-jacent, cette étude a aidé à réaliser un problème concernant la complétude des données et à le traiter sérieusement.
Ce problème peut être évité ou largement atténué, si les sondes sont correctement choisies comme source de données de mesure.
Avec des données complètes et relativement complètes au fil du temps, de nombreuses étapes de nettoyage de données peu justifiables peuvent être évitées.

\subsection{La variation supplémentaire dans les mésures de latence}

Un problème de qualité des données spécifique dans TE de l'interdomaine est \textit{si la mesure RTT reflète principalement les caractéristiques des chemins AS}.

La fonction de sélection d'itinéraire dans la figure~\ref{fig: archi} repose sur les mesures de performance de chemin (plus de détails dans le chapitre~\ref{sec: cpt_rtt}).
Toutefois, les mesures RTT peuvent être ``polluées'' par des facteurs non liés au réseau, par exemple des problèmes locaux tels que la surcharge du processeur,
 ou des problèmes de réseau de niveau sub-AS non représentatifs, par exemple la congestion locale du réseau de la destination.
Éviter ces problèmes n'est pas l'objectif principal de TE dans l'interdomaine, car ce dernier tout seul ne se suiffit pas.
Cependant, aucun de ces travaux antérieurs~\cite{Goldenberg2004, Akella2008} n'a réalisé l'importance de ce problème.

Ce problème de qualité des données soulève une série de questions:\textit{si nous mesurons un même chemin AS avec différents hôtes dans le préfixe de la destination, 
à quoi ressembleront ces différentes éries temporelles RTT? 
Auront-ils des traits similaires? 
Si non, comment pouvons-nous choisir celles qui conviennent le mieux aux fins de TE dans l'interdomaine?}
Nous essayons de répondre à ces questions en effectuant des regroupements sur un tel ensemble de séries temporelles de RTT.
Sans connaissance préalable ou hypothèse, l'étude vise à révéler automatiquement les structures inhérentes de ces séries temporelles de RTT.

Dans cette étude, nous avons analysé des séries temporelles RTT entre deux AS.
Nous avons découvert que les séries temporelles de RTT recueillies dans cette étude démontrent diverses formes de variation, 
bien qu'un chemin d'AS en commun soit mesurée.
Il a confirmé que les mesures RTT doivent être ``nettoyée''.
Nous avons regroupé ces séries temporelles RTT en extrayant
plusieurs caractéristiques comme leur représentation.
Les clusters résultants ont réussi à séparer les traces bruyantes des traces lisses selon l'intuition humaine et l'expertise.
De plus, nous avons localisé l'emplacement de la plupart des variations dans les mesures RTT de bout en bout en appliquant les méthodes de regroupement aux premiers sauts des mesures traceroute.
Nos résultats ont confirmé le bon sens que la plupart des variations proviennent du réseau d'accès.

Time series clustering

Un cluster de séries chronologiques RTT, illustré dans la figure ~ \ ref {fig: cls8_k12}, contient plusieurs mesures RTT subissant une variation RTT de forme similaire en même temps.
Ce changement RTT n'est pas observé sur d'autres mesures RTT dans l'ensemble de données.
Les implications sont qu'une partie commune exclusive à ces mesures RTT dans la figure ~ \ ref {fig: cls8_k12} aurait pu provoquer ce changement.
Inférer l'emplacement responsable des changements RTT dans Internet est un sujet intrigant dans son propre droit.
De plus, il contribue à une meilleure logique de sélection d'itinéraire, si elle est réalisable avec seulement des mesures de temps et de trajet de bout en bout.

La mise en grappes dans l'espace caractéristique (section ~ \ ref {sec: cls_ft}) n'est cependant pas la meilleure option pour l'identification de séries temporelles RTT avec des formes similaires.
C'est parce que les entités extraites, résumant l'ensemble des séries temporelles, n'ont pas l'expressivité sur la structure temporelle.
Par conséquent, nous étudions les approches de clustering où la représentation des données des séries chronologiques RTT reste une série chronologique.

Le clustering de séries chronologiques avec \ textbf {MP} / \ textbf {Seg} et \ ac {PAM} a offert des résultats très intéressants et nous a aidés à poursuivre un cas spécifique de changement RTT partagé par plusieurs séries temporelles RTT.
Toutefois, il n'est toujours pas idéal dans le contexte de TE basé sur la mesure pour les raisons suivantes.

Premièrement, il ne sera pas à l'échelle. Afin d'obtenir une matrice de distance parmi les séries de temps $ n $, un calcul de distance de $ O (n ^ 2) $ est nécessaire. Le coût de calcul pour la mise en grappe pourrait donc être prohibitif lorsqu'il existe des milliers de séries chronologiques RTT, une pour chaque préfixe de destination.

Deuxièmement, l'interprétation des résultats de regroupement reste ponctuelle et donc difficile à automatiser.
\ ac {ASW} de chaque cluster peut servir d'indicateur de la qualité / pertinence du cluster.
Pourtant, quel niveau de \ ac {ASW} devrait être considéré comme suffisamment important est difficile à justifier.
Dans les analyses précédentes, nous avons toujours eu recours à des séries RTT brutes pour juger si les grappes sont significatives ou non, avant d'effectuer une analyse plus spécifique.
En plus de cela, les résultats de la mise en cluster ne précisent pas quand les changements RTT partagés par les membres du cluster se produisent réellement, empêchant ainsi une investigation systématique des événements réseau liés à ces moments.

Troisièmement, il est difficile de transformer le regroupement en un processus en ligne.
Au fil du temps, différentes parties d'Internet peuvent provoquer des changements RTT et avoir un impact sur différents ensembles de mesures RTT.
Par conséquent, différentes grappes sont attendues au fil du temps.
Cela nécessite que les méthodes de mise en cluster mettent à jour les clusters résultants lorsque de nouvelles mesures sont intégrées.
Les méthodes de regroupement étudiées dans ce chapitre sont clairement inadaptées.

Pour résoudre les problèmes ci-dessus, nous avons trouvé que la simplification des séries temporelles RTT via la détection de points de changement était prometteuse.
Sa puissance a déjà été démontrée avec la représentation des données \ textbf {Seg}.
Il produit d'abord les moments où chaque série chronologique RTT connaît des changements importants.
Sur la base de ce statut binaire de changement ou non, nous pouvons alors facilement former des groupes de séries temporelles partageant le même changement.
Avec les groupes en évolution, nous pouvons suivre les causes des différents changements RTT au fil du temps sur Internet.
Nous développons cette idée dans le chapitre ~ \ ref {sec: cpt_rtt} et ~ \ ref {sec: infer}.

RTT change detection

Les mesures RTT interviennent dans l'interdomaine TE basé sur la mesure à deux phases.
Premièrement, les mesures RTT révèlent les moments où la resélection de l'itinéraire est nécessaire. % sinon la performance de transmission peut subir une dégradation évitable.
Deuxièmement, les mesures RTT servent de matériel de prise de décision dans la resélection de la route. Nous nous reportons sur le délai mesuré, les coûts de transmission et les politiques de routage, etc., pour décider quel chemin / fournisseur de transit est le meilleur choix pour atteindre chaque destination à un certain moment.
Nous discutons dans ce chapitre de l'utilisation des mesures RTT pendant la première phase.

Les moments où la re-sélection de route est nécessaire sont essentiellement lorsque les performances sur certains chemins AS changent.
Le défi de la détection de changement de performance provient principalement de deux aspects.
Premièrement, les mesures RTT sont bruyantes.
De nombreux facteurs le long du trajet mesuré peuvent contribuer aux variations du délai de bout en bout, par ex. fluctuation de la charge de l'hôte final, circulation en rafale, etc.
Cela nécessite des méthodes de détection du changement pour tolérer des bruits tels que de courtes pointes de vie, tout en restant sensible aux événements qui comptent vraiment, tels que la congestion persistante.
Deuxièmement, les caractéristiques de retard sur différents chemins peuvent différer beaucoup.
Il est donc souhaitable de détecter les changements pour ces séries chronologiques sans paramètres dépendant du chemin / destination.
Beaucoup de pratiques courantes ne répondent pas aux exigences énumérées ci-dessus.

Dans cette section, nous résumons les études précédentes sur les variations RTT et leur relation avec les événements réseau.
Nous expliquons pourquoi certaines méthodes d'analyse RTT adoptées dans les travaux mentionnés ne conviennent pas aux utilisations de TE.

% Les changements de chemin et l'encombrement sont connus pour être les principales raisons des changements RTT.
Il est généralement admis que les changements de routage inter-domaines ont un impact important sur le niveau RTT.
Pucha et al. ~ \ Cite {Pucha2007} ont montré que les changements de routage inter-domaines entraînent une plus grande variation RTT médiane que les changements intra-domaine.
Rimondini et al. ~ \ Cite {Rimondini2014} ont confirmé que des changements de route de 72,5% $ BGP dans leur étude sont associés au changement RTT.
%% Mesure de RIPE Atlas et RIPE RIS en 2013, seulement 55 AS sont considérés.
Des observations similaires ont été faites dans un grand \ ac {CDN}, où les changements de routage inter-domaine sont responsables de plus de 40 $ \% $ de dégradation de l'expérience utilisateur sévère ~ \ cite {Zhu2012}.

Les événements intra-domaine ne sont pas moins importants. Pucha et al. ~ \ Cite {Pucha2007} ont découvert que les changements de chemin intra-domaine peuvent provoquer des changements RTT d'amplitude comparable à ceux inter-domaine.
En outre, ils ont souligné que ce sont les changements de chemin intra-domaine, et non la congestion, qui sont responsables de la majorité (86% $) des changements de RTT. % au lieu de la congestion.
Une affirmation différente a cependant été faite par Schwartz et al. ~ \ Cite {Schwartz2010}. Ils ont découvert que la plupart des variations RTT se situaient plutôt dans les chemins (c'est-à-dire en raison de l'encombrement) que parmi les chemins (c'est-à-dire en raison des changements de chemin).

Les conflits dans les travaux antérieurs pourraient être causés par la différence des emplacements d'où les mesures ont été lancées.
Par exemple, Chandrasekaran et al. ~ \ Cite {Chandrasekaran} ont observé que les changements de chemin d'AS n'ont qu'un impact marginal sur RTT dans le noyau d'Internet, alors que les travaux précédents ~ \ cite {Pucha2007, Schwartz2010} incluent aussi des réseaux d'accès.
Les résultats pourraient aussi changer avec le temps. Par exemple, la topologie Internet "aplatie", la quantité croissante de trafic privé CDN au cours de la dernière décennie ~ \ cite {Labovitz2011, Roughan2011} pourrait avoir modifié les caractéristiques du changement de chemin et de la congestion, et par conséquent, leur impact sur RTT.

En gardant cela à l'esprit, nous aimerions souligner les efforts sur les méthodes et les outils.
Au-delà de l'observation ou de l'analyse ponctuelle sur un ensemble de données spécifique, ils permettent une analyse itérative dans le temps.

La discussion et la découverte des travaux précédents sont éclairantes, mais leurs méthodes de traitement de mesure RTT peuvent difficilement être appliquées à l'intra-domaine TE.
Dans ~ \ cite {Pucha2007, Schwartz2010, Chandrasekaran},
Les mesures RTT sont d'abord groupées par des chemins sous-jacents;
l'impact des changements de trajet est ensuite estimé par la comparaison des statistiques RTT associées, par ex. centiles.
Cependant, dans un système TE pratique esquissé dans la figure ~ \ ref {fig: archi}, les RTT sont mesurés avec une fréquence plus élevée que les chemins.
Les raisons sous-jacentes sont triples.
Premièrement, les mesures RTT sont en général moins coûteuses.
Compte tenu du nombre potentiel de destinations à surveiller (voir section ~ \ ref {sec: pref_selec}), les mesures de chemin sont mieux limitées.
Deuxièmement, un RTT plus petit est l'objectif de TE, nous avons donc l'incitation à suivre de près son évolution. Pendant ce temps, le chemin est juste le résultat de l'optimisation.
Troisièmement, les changements RTT se produisent généralement plus fréquemment que les changements de chemin.
Une raison importante est la congestion.
Le regroupement des mesures de RTT par des changements de trajectoire ne peut éclairer la présence de
de tels événements.
Par conséquent, nous devons explorer des méthodes qui permettent d'identifier les changements RTT inhérents, au lieu de s'appuyer sur des mesures externes telles que les changements de trajectoire pour décrire la variation des performances de transmission.

Parmi les études approfondies sur les méthodes de détection des changements et leurs applications dans divers domaines ~ \ cite {Zhang2007, Reeves2007, Yu2008},
Rimondini et al. ~ \ Cite {Rimondini2014} sont parmi les premiers à utiliser la détection de changement dans l'analyse de mesure de RTT de réseau.
Cependant, ils ont réglé la sensibilité de détection de telle sorte que les changements détectés correspondent le mieux aux changements de route BGP vers le préfixe de destination mesuré parmi d'autres préfixes choisis au hasard.
Cette approche risque d'ignorer les changements RTT dus aux changements intra-domaine et à l'encombrement.
De plus, un tel réglage est potentiellement nécessaire pour chaque destination individuelle, donc difficile à mettre à l'échelle.
Pour obtenir une approche plus générale découplée des mesures de trajectoires, nous proposons dans la section suivante un cadre d'évaluation pour la sélection et l'étalonnage des méthodes de détection des changements par rapport aux mesures RTT.

Quelle méthode (parmi la grande variété de ceux existants) est la plus appropriée pour les séries temporelles Internet RTT n'est toujours pas indiqué.
De plus, de nombreuses méthodes de détection de points de changement sont paramétriques.
Identifier les meilleurs paramètres pour ces méthodes reste aussi difficile.
L'absence d'un cadre d'évaluation est un problème fondamental pour résoudre les problèmes susmentionnés.

Un cadre d'évaluation quantifie la performance d'une certaine méthode de détection sur un ensemble de données de référence.
Avec l'évaluation quantifiée, différents paramètres d'une même méthode ou différentes méthodes peuvent être comparés et réglés pour fournir les meilleurs résultats de détection.
Naturellement, un cadre d'évaluation devrait être composé de deux parties: 1) des ensembles de données de "vérité de terrain", 2) une méthode de notation.

Le jeu de données de `` vérité de terrain '' n'est pas seulement un ensemble de séries temporelles RTT représentatives des caractères de retard sur Internet.
Il devrait aussi porter des étiquettes indiquant les moments de changement dans ces séries chronologiques.
Nous ne sommes pas au courant d'un tel ensemble de données qui soit publiquement disponible à ce jour.
% Nous avons étiqueté manuellement 50 séries temporelles réelles RTT de RIPE Atlas contenant 408 087 mesures RTT.
% Les détails sont donnés dans la section ~ \ ref {sec: label}.
Nous expliquons dans la section ~ \ ref {sec: label} comment nous construisons un jeu de données de vérité au sol avec beaucoup de soin.

Quant à la méthode de notation, elle quantifie la similarité / différence entre la "vérité de terrain" et les points de changement détectés.
Nous expliquons dans la section ~ \ ref {sec: score} que la classification classique vrai / faux positif est trop rigide pour l'étiquetage manuel et la détection de point de changement.
Nous explorons et relevons les défis de la comparaison de deux ensembles d'horodatages avec la tolérance de décalage temporel.

Afin de déterminer quelle méthode de détection fonctionne le mieux sur RTT timeseries,
un ensemble de données avec \ textit {a priori} moments marqués de changement RTT est nécessaire, servant de vérité terrain.
C'est la qualité est essentielle à la crédibilité des résultats de l'évaluation.

Il existe deux approches pour fabriquer un jeu de données de vérité au sol étiqueté: 1) des données générées artificiellement; 2) des données réelles avec des étiquettes mises manuellement.
Évidemment, les données réelles sont plus représentatives du caractère de retard d'Internet.
C'est donc le choix préféré.
Cependant, il ne peut être étiqueté que par des humains ayant des connaissances du domaine.
L'étiquetage manuel est fastidieux et sujet aux erreurs.
Sans le moindre soin, cela peut nuire à la qualité de l'ensemble de données de la vérité au sol.
De plus, l'identification de changements significatifs dans les séries temporelles RTT est dépourvue d'une norme opérationnelle.

Par conséquent, il est important de vérifier la qualité de l'étiquetage.
À cette fin, nous comptons sur un ensemble de données artificiel.
L'idée est de générer des timeseries synthétiques RTT avec des points de changement connus.
Ces séries temporelles artificielles sont ensuite mélangées à de véritables séries RTT au cours de l'étiquetage humain.
Une fois l'étiquetage effectué, nous comparons les points de changement étiquetés par l'homme sur l'ensemble de données artificiel avec les points de changement générés, en utilisant la méthode de notation présentée dans la section ~ \ ref {sec: score}.
C'est pour évaluer la performance de détection des étiqueteuses humaines en utilisant les changements générés comme vérité au sol.

Les temporisations RTT synthétiques sont après tout des mesures RTT non réelles.
Les étiqueteuses humaines fonctionnant parfaitement sur des traces générées n'indiquent pas nécessairement qu'elles feraient aussi bien sur de vraies mesures RTT.
Par conséquent, il est hautement souhaitable que les timeseries artificielles RTT ressemblent autant que possible aux réels.
Les étapes suivantes sont suivies pour générer une série temporelle RTT synthétique.

Premièrement, nous générons de manière aléatoire plusieurs phases / segments de lignes de base différées différentes.
Différentes lignes de base RTT correspondent aux différentes longueurs physiques sur différents chemins Internet.
Pour chaque phase de RTT baseline, nous ajoutons des bruits représentant les changements de longueur de la file d'attente micro, le temps d'attente dû à la charge du routeur et aux politiques de programmation, etc.
Enfin, pour chaque phase de RTT de base, nous générons relativement longtemps pendant la congestion avec son propre processus de Markov.
Les paramètres aléatoires appropriés à chaque segment de base déterminent les chances d'entrer et de sortir d'une période de congestion.
Les points de changement générés sont des moments où il y a des changements de délai de base et d'entrée / sortie de congestion.
Les pics de vie courts (longueur $ \ leq 2 $ points de données) sont considérés comme des bruits plutôt que de réels changements.
Pour les modèles génératifs détaillés et les paramètres de modèle de chaque étape, veuillez vous référer à la documentation dans l'espace de code disponible sur \ url {https://github.com/WenqinSHAO/rtt_gen.git}.

20 timeseries synthétiques RTT, avec 6485 points de données chacun en moyenne, sont générés avec l'outil fabriqué.
L'intervalle de temps entre les points de données est de 4min, conformément à la mesure ping intégrée de RIPE Atlas.
Ils représentent 8646 heures de mesures RTT avec 935 points de changement générés.
Un exemple de ces traces RTT synthétiques est représenté sur la figure ~ \ ref {fig: art_example}.
Les lignes verticales rouges, indiquant les points de changement générés, sont des moments où il y a un changement de RTT de ligne de base, ou une période de congestion commence / finit.

Avec le cadre d'évaluation prêt, il ouvre la porte à l'exploration de la méthode de détection des points de changement les plus performants pour les mesures RTT.
Pour la famille de détection présentée dans la section ~ \ ref {sec: cpt}, deux principaux paramètres doivent être définis: la pénalité et la fonction / distribution des coûts.
Nous discutons en détail ces paramètres dans cette section, tout en laissant l'examen d'autres méthodes pour les travaux futurs.

Nous considérons la combinaison entre tous les critères d'information introduits (AIC, BIC, MBIC et Hannan-Quinn), et tous les types de distribution supportés, y compris l'approche non-paramétrique basée sur la distribution empirique.

Avec quelques tests préliminaires, nous avons rapidement réalisé que la détection avec la distribution normale tend à être sur-sensible, sous tous les réglages de pénalité.
Beaucoup de bruits de vie courts et insignifiants sont marqués comme points de changement.
C'est parce que la moyenne et la variance de la distribution normale sont indépendamment contrôlées par deux paramètres distincts, ce qui augmente les chances de s'adapter à des changements subtils de niveau ou de volatilité.
D'un autre côté, les distributions exponentielle, gamma et de Poisson sont trop engourdies.
La moyenne et la variance de Poisson et de la distribution exponentielle sont couplées par un paramètre,
qui restreint leur liberté d'ajustement ~ \ footnote {Poisson, mean = variance = $ \ lambda $; Exponentiel, moyenne / variance = $ \ lambda $, moyenne = $ 1 / \ lambda $.}.
La distribution gamma est confrontée au même problème, mais avec une histoire plus compliquée.
Une distribution gamma peut être décrite par deux paramètres $ \ alpha $ et $ \ beta $: mean = $ \ frac {\ alpha} {\ beta} $, variance = $ \ frac {mean} {\ beta} $.
\ cite {Killick2013a}, l'implémentation que nous utilisons, nécessite une entrée \ textit {a priori} pour $ \ alpha $, qui détermine en fait la sensibilité globale.
Seul $ \ beta $ est ajusté pour détecter les points de changement.
Avec un plus grand $ \ alpha $, un $ \ beta $ plus grand est nécessaire pour maintenir la même estimation moyenne pour un segment donné.
Une moyenne fixe avec un plus grand $ \ beta $ impose une plus petite tolérance de variation, donc plus susceptible de diviser le segment donné en raison de changements de variance plus petits.
En bref, un plus grand $ \ alpha $ conduit à une détection plus sensible.
L'option par défaut définit $ \ alpha $ sur 1, ce qui dégénère la distribution Gamma en distribution exponentielle.
Nous avons également essayé $ \ alpha $ de 1 à 100, à l'étape unitaire.
Aucun d'entre eux ne surpasse les meilleurs paramètres affichés plus tard.
Nous ne considérons donc plus les distributions gamma.

En supposant une distribution exponentielle et de Poisson, nous remarquons que le niveau moyen d'une série chronologique RTT dicte d'une certaine manière la tolérance de variation.
Par exemple, pour un chemin incluant des liaisons transpacifiques, nous nous attendons à un RTT minimum supérieur à 80msec $.
Dans ce cas, la distribution de Poisson correspondante pourrait facilement tolérer plusieurs déviations RTT de 20 msec $, ce qui est déjà non négligeable.
Cependant, le fait d'avoir une moyenne et une variance couplées peut aussi être une caractéristique désirée.
Nous avons observé au cours de l'étiquetage que le niveau d'un segment RTT et sa variance sont souvent positivement liés au cours des périodes de congestion.

Pour tirer parti de la caractéristique décrite ci-dessus et augmenter la sensibilité de détection, nous proposons pour la distribution exponentielle et de Poisson un \ textit {transformation de données}: soustraire la série temporelle RTT par sa valeur minimum (baseline) pour abaisser son niveau RTT global ~ \ footnote {Notez que les mesures de temporisation sont définies sur 1000ms.
Pour les distributions de Poisson, les valeurs RTT sont arrondies à l'entier le plus proche.
Les modifications sont ensuite détectées pour la série temporelle RTT supprimée en base lorsque l'on suppose une distribution de Poisson et exponentielle.
Ce paramètre est noté \ texttt {cpt \ _poisson} et \ texttt {cpt \ _exp} respectivement.
Par souci de comparaison, nous considérons également la distribution de Poisson \ textbf {sans transformation de données} et nous l'indiquons comme \ texttt {cpt \ _poisson \ _naive}.
La distribution normale et l'approche non-paramétrique sont appliquées directement sur les mesures RTT initiales.

Toutes les combinaisons entre les types de distribution et les choix de pénalité sont utilisées pour détecter les points de changement dans l'ensemble de données de vérité au sol.
Pour chaque type de distribution, nous plaçons seulement son paramètre de pénalité le plus performant en termes de score $ F_2 $ pondéré dans la figure ~ \ ref {fig_eval_eval}.
Dans une discussion ultérieure, lorsque nous mentionnons un type de distribution spécifique, disons \ texttt {cpt \ _poisson}, nous nous référons à une configuration incluant la distribution elle-même, la transformation de données correspondante et son choix de pénalité le plus performant.

Plus de 75 $ \% $ de changements, en termes de poids, peuvent être détectés pour plus de la moitié des séries temporelles avec l'une de ces distributions.
Tous ces types de distribution ont une meilleure pondération $ F_2 $ que le classique $ F_2 $, indiquant que certains points de changement manqués sont en effet de peu d'importance opérationnelle.
Cependant, il semble avoir un grand espace pour des améliorations.
Des efforts sont particulièrement nécessaires pour augmenter la précision des résultats de la détection.

La précision de \ texttt {cpt \ _normal} est particulièrement mauvaise.
Cela confirme que \ texttt {cpt \ _normal} est en effet sur-sensible pour le type de données RTT ~ \ footnote {Notez que la meilleure pénalité de \ texttt {cpt \ _normal} est MBIC, le plus grand paramètre de pénalité adaptative. Cela signifie que la détection sensible est déjà supprimée à son maximum.
Au contraire, le rappel de \ texttt {cpt \ _normal} est remarquable parmi tous les candidats.
Cependant, ses scores $ F_2 $ sont les plus faibles ~ \ footnote {Avec $ F_2 $, le rappel est déjà pondéré deux fois plus important que la précision.}.
La piètre performance globale de la détection souligne l'importance de trouver un juste équilibre entre sensibilité et pertinence.
Il suggère également que la qualité de l'ajustement n'est pas une garantie de performances de détection.
Pour les méthodes de repos, leurs performances sont relativement proches.
Par rapport à \ texttt {cpt \ _poisson \ _naive} (sans transformation de données), \ texttt {cpt \ _poisson} obtient un rappel plus élevé et un rappel pondéré sans sacrifier de façon évidente la précision.
Par conséquent, \ texttt {cpt \ _poisson} présente un léger avantage sur les performances globales.
En fait, sans transformation de données, en supposant que la distribution exponentielle ne détecte aucun point de changement pour une grande partie des séries temporelles dans l'ensemble de données de vérité au sol.
Ce sont toutes des preuves que la transformation de données proposée améliore les performances de détection pour la distribution de Poisson et exponentielle.

Dans cette section, nous détectons les changements de chemin rencontrés par les mesures RTT collectées.
Les changements de chemin de niveau AS et IP sont pris en compte.
Ils sont connus pour avoir un impact potentiel sur RTT.
La mesure de trajectoire intégrée RIPE Atlas utilise un paramètre de rotation Paris ID.
Cela crée une confusion entre les changements de chemin IP provoqués par l'équilibrage de charge et ceux dus aux changements de routage intradomaine.
Nous abordons ce problème dans cette section.
% afin d'explorer en profondeur la différence de sensibilité de détection avec différents paramètres et la pertinence de la détection par rapport aux changements de chemin, les événements de réseau connus pour avoir des conséquences sur RTT.
Le but de la détection de changement de chemin n'est pas de répéter certaines des études présentées dans ~ \ ref {sec: rtt_path},
tel que quel type de changement de chemin contribue le plus au changement RTT.
Cela aide plutôt à améliorer la compréhension de la détection des points de changement pour les mesures RTT.

La table ~ \ ref {tab: corr_overview} détaille le nombre de correspondances entre les changements de chemin et de RTT.
Chaque cellule indique le nombre de correspondances entre la ligne correspondante (type de changement de chemin) et la colonne (méthode de détection de changement RTT).
La dernière colonne contient le nombre total de changements de chemins de chaque type.
De même, la dernière ligne fournit le nombre total de changements RTT détectés par les deux méthodes.

La fraction des changements de chemin d'AS correspondant aux changements de RTT par l'une ou l'autre méthode de détection est beaucoup plus faible que le $ 72.5 \% $ in \ cite {Rimondini2014} rapporté.
Il semble que les changements de chemin AS ont un impact moins significatif sur RTT que la compréhension précédente.
Y a-t-il quelque chose de particulier dans notre ensemble de données ou nos méthodes?
De plus, le nombre de changements de chemin d'AS correspondant à \ texttt {cpt \ _np} le changement de RTT n'est que de la moitié de celui avec les modifications RTT de \ texttt {cpt \ _possion}.
Au contraire, les nombres correspondants pour les changements d'IXP et de \ AC {IRP} sont assez proches entre les deux méthodes de détection de changement RTT.
D'où vient cette différence?
Tous ces phénomènes sont très intrigants.
Nous essayons d'explorer les raisons sous-jacentes dans la section suivante avec un regard en gros plan.

Plusieurs raisons contribuent à la grande quantité et à la fraction des changements de RTT inégalés à tous les changements de chemin.
D'abord, les changements sur le chemin inverse ne sont pas observés.
Nous n'avons pas été en mesure de mesurer le chemin inverse avec la mesure intégrée RIPE Atlas.
Par conséquent, il est impossible de détecter les changements sur le chemin inverse.
Cependant, ces changements pourraient avoir contribué aux changements RTT.
Notamment dans le contexte du routage inter-domaines où les chemins risquent d'être asymétriques.
Cela implique que les changements RTT provoqués par les changements de chemin inverse sont probablement différents de ceux provoqués par les changements de chemin dans la direction d'acheminement.

Deuxièmement, la congestion.
La congestion peut être indépendante des changements de chemin et pourtant elle peut causer des variations RTT significatives.
La figure ~ \ ref {fig: case_26328} donne un exemple typique de changements RTT probablement causés par la congestion.
Il y a trois bosses qui peuvent être visuellement remarquées dans les temps RTT tracés.
Nous disons que les deux derniers sont probablement de la congestion.
Premièrement, ils ne correspondent à aucun changement de chemin, au moins dans la direction d'acheminement.
Deuxièmement, ces bosses sont probablement causées par le remplissage des files d'attente le long du chemin.
Parce que, les RTT dans ces bosses ne sont pas plates.
Sur un chemin légèrement chargé, nous nous attendons à des mesures RTT relativement constantes.
C'est parce que les files d'attente sont presque vides, donc pas de place pour la variation de délai.
D'un autre côté, la modification des RTT à l'intérieur de la bosse est probablement le reflet de l'évolution de la demande de trafic sur le goulot d'étranglement due au mécanisme de contrôle de congestion de bout en bout.
Les deux bosses / congestion s'écartent grandement de la ligne de base et durent plusieurs heures.
Ils ont donc un impact significatif sur les performances de transmission.
Nous les avons détectés avec succès avec les méthodes de détection des points de changement étudiés.
Cependant, une telle détection n'est pas possible avec la méthode précédemment proposée ~ \ cite {Luckie2014}.
Il effectue une analyse spectrale sur RTT timeseries pour trouver périodiquement congestion répétée.
Une telle congestion persistante est normalement due au manque de capacité du réseau.
Pendant ce temps, la congestion transitoire dans la figure ~ \ ref {fig: case_26328} est plus probablement causée par des variations de trafic soudaines.
L'ET basé sur la mesure vise à éviter les deux types de congestion lorsqu'il existe des chemins alternatifs avec la capacité disponible.
A cet effet, les méthodes de détection des points de changement sont en effet utiles pour notifier la présence de telles variations de performance.

Troisièmement, la détection sur-sensible.
Si nous supposons hardiment que les changements de chemin sur les chemins de retour provoquent une quantité comparable de changements de RTT comme le font les changements de chemin d'acheminement, il y a encore de nombreux changements de RTT non appariés.
Certains d'entre eux pourraient être effectivement attribués à la congestion, comme expliqué ci-dessus.
Les modifications RTT non appariées restantes sont manifestement le résultat d'une détection trop sensible.
Nous avons déjà révélé à partir d'une vue macroscopique, dans Section ~ \ ref {sec: cpt_trace} et ~ \ ref {sec: as_match_diff}, que \ texttt {cpt \ _poisson} a tendance à surestimer le nombre de points de changement lorsque la trace RTT est bruyante.
Pendant ce temps, \ texttt {cpt \ _np} est capable de détecter les changements délicats de RTT.
Des traces individuelles sont données sur la figure ~ \ ref {fig: case_sensitivity} pour illustrer la différence de sensibilité à partir d'une vue microscopique.
Dans la figure ~ \ ref {fig: case_28002}, \ texttt {cpt \ _np} a détecté toute la congestion périodique de petite amplitude.
C'est en fait assez impressionnant, car ces changements sont à peine visibles pour les experts humains.
Les points de changement marqués par \ texttt {cpt \ _np} ont en effet mis en évidence leur présence, et les ont rendus plus faciles à remarquer visuellement.
Dans la figure ~ \ ref {fig: case_26328}, les deux méthodes ont identifié les deux grandes bosses près de la fin de la série temporelle.
La différence est que \ texttt {cpt \ _poisson} a également marqué les changements de niveau intermédiaire.
Ces points de changement intermédiaires ne sont clairement corrélés à aucun changement de chemin.
En plus de cela, ils sont également redondants en informant la congestion qui se produisait à ce moment-là.
La raison d'une telle sur-sensibilité était due à son incompétence dans l'ajustement de la sensibilité de détection en fonction du niveau de variance d'entrée. Ce problème est exploré et expliqué dans la section ~ \ ref {sec: over_sensitive}.

Cause inference

Comme expliqué dans le chapitre ~ \ ref {sec: intro}, afin de mesurer la performance du chemin vers un préfixe de destination, nous devons, en premier lieu, identifier certains hôtes dans ce préfixe qui répondent à nos mesures.
Une approche possible les identifiant est de rechercher des hôtes écoutant sur certains ports TCP communs, par ex. 80, 443, etc., dans le trafic échangé avec ce préfixe de destination ou via un balayage de port.
Puis RTT vers le préfixe de destination est représenté par les mesures vers les hôtes identifiés ~ \ footnote {Il existe plusieurs façons de mesurer activement le RTT via TCP. Les méthodes avec peu d'encombrement et un faible coût de mesure sont utilisées dans le balayage des ports ~ \ cite {nmap}, comme SYN (également connu sous le nom de semi-ouvert) ou furtif FIN.}.

% \ marginpar {Manque de mesure directe vers certains préfixes de destination.}
Cependant, tous les préfixes de destination sélectionnés n'ont pas ces hôtes `mesurables '~ \ footnote {préfixes sélectionnés: préfixes de destination avec un volume important ainsi sélectionné pour TE, plus de détails dans Section ~ \ ref {sec: pref_selec}.}.
Take client SA est apparu dans la section ~ \ ref {sec: pref_selec} à titre d'exemple.
En moyenne, 15% de son trafic sortant impliquant des préfixes de destination $ \ sim 330 $ sont sans mesures.
Plus de 70% du trafic "non mesuré" s'écoule vers des préfixes appartenant aux opérateurs mobiles pendant les heures de pointe.
Dans un avenir prévisible, la proportion d'un tel trafic serait encore plus importante, compte tenu de la tendance générale à l'augmentation de l'utilisation des appareils mobiles.
À ce stade, nous sommes confrontés au problème de \ textit {effectuant un TE basé sur des mesures sans mesure directe vers la destination}.

Sans les mesures RTT vers P4 dans la figure ~ \ ref {fig: chap5_cause_infer_te}, nous n'avons aucune idée sur quand et lequel de ses chemins disponibles pourraient subir des changements et sont donc incapables de prendre des décisions TE.
Cependant, si nous étions en mesure de déduire quelle partie de l'Internet est responsable des changements RTT en utilisant les mesures disponibles, nous pourrions encore avoir une chance d'optimiser pour P4.
Supposons que le lien entre AS2 et AS3 soit déduit (d'une certaine manière) comme étant la cause du changement RTT subi par des mesures vers P2 et P3.
Comme un chemin vers P4 (la ligne pointillée) circule aussi par AS2 et AS3, nous pouvons alors raisonnablement supposer que la performance de transmission vers P4 sur ce chemin connaîtra un changement similaire au même moment que ceux vers P2 et P3.
En réalisant cela, nous allons passer à des chemins alternatifs qui restent inchangés pour atteindre P4.
C'est ainsi que la RTT change parce que l'inférence éclaire les variations de performance vers des destinations sans mesures directes et donc permet à TE.

Cette idée a d'abord été inspirée par l'étude de cas dans Section ~ \ ref {sec: ripe_case_study} sur les changements RTT partagés par plusieurs séries temporelles RTT provenant de différents AS.
Nous avons réalisé que certains changements RTT ne sont pas exclusifs aux mesures sur un chemin Internet spécifique, mais impactent plutôt plusieurs séries temporelles RTT simultanément, comme le montre la figure ~ \ ref {fig: rtt3d_mp_cls2}.
Optimiser le routage interdomaine contre la cause de tels changements de RTT serait alors une approche plus fondamentale et plus efficace de TE que de traiter chaque préfixe individuel et chaque chemin vers eux.

Afin de déduire l'emplacement des causes, une hypothèse raisonnable est que de tels changements RTT partagés sont plus probablement causés par les parties communes de ces chemins, au lieu d'être la conséquence de la synchronisation parfaite de plusieurs problèmes dispersés dans divers endroits.
Avec cela, il est alors possible d'affiner la portée des causes possibles avec des mesures ayant à la fois des parties communes et des parties divergentes.
Un exemple de jeu d'inférence est donné dans la figure ~ \ ref {fig: chap5_toy_inference}.
Avec l'hypothèse, nous pouvons d'abord étendre la cause aux liens 1 et 4, aux nœuds 2 et 5.
Comme il y a une mesure sans changement de RTT, le lien traversant 1 et le nœud 2, le lien 4 et le nœud 5 sont alors plus susceptibles d'être la cause.
Dans la section ~ \ ref {sec: inference}, nous décrirons plus formellement les hypothèses et la logique d'inférence pour l'investigation des nœuds et des liens sous tous les modèles de topologie et distributions de mesures possibles.

Avec le changement RTT cause l'inférence, nous sommes intéressés à identifier la partie de l'Internet, aussi précise que possible, qui est responsable des changements RTT détectés.
Ce que nous avons en entrée sur les plates-formes TE client est 1) les mesures RTT provenant de sources multiples vers des destinations multiples pour les utilisations TE; 2) les chemins AS sous-jacents pour ces mesures RTT ~ \ footnote {Avec le système TE réel, les sources de mesures sont les plates-formes clientes et les destinations sont les préfixes auxquels les clients envoient du trafic.
La source des mesures peut être multiple si nous fusionnons des mesures à partir de plusieurs plates-formes clientes ou si le client a plusieurs sites avec différentes options de fournisseur.}.

La figure ~ \ ref {fig: chap5_sys_design} décrit les blocs de construction logiques requis pour l'inférence du changement de RTT. La détection de point de virage (section ~ \ ref {sec: cpt_rtt}) symbolise les temporisations RTT en séquences d'événements de changement RTT.

La construction de la topologie construit un graphique pour les sauts et les liaisons traversés par les mesures RTT.
Ce graphe de topologie est une étape intermédiaire dans la conception d'une métrique d'inférence pour chaque noeud et chaque lien présents dans la topologie. Comme on le voit sur la figure ~ \ ref {fig: chap5_toy_inference}, si un nœud / lien est la cause du changement RTT, dépend non seulement des mesures qui le traversent, mais aussi de celles qui circulent. L'identification de tels ensembles de mesures pour chaque nœud / lien nécessite des connaissances sur la topologie. De plus, le graphe de topologie sert aussi à visualiser l'emplacement des changements RTT.

La valeur exacte de ces métriques d'inférence à chaque instant est calculée à partir de séquences d'événements de changement RTT. Ensuite, l'inférence de cause est effectuée pour chaque noeud et chaque lien en fonction de la valeur de leurs métriques d'inférence.
% Les séquences d'événements de modification RTT instancient les métriques d'inférence sur lesquelles l'inférence de cause est effectuée.
La sortie de l'ensemble du système indique les liens et les noeuds responsables des changements RTT dans le temps.

Afin d'initier l'inférence, nous avons fait deux hypothèses.

\ begin {supposition} {1} {unique cause} \ label {as: 2}
Pour chaque changement RTT détecté, il n'y a qu'une seule cause, nœud ou lien, sur le chemin mesuré.
\ end {hypothèse}
C'est une hypothèse courante faite dans les études de congestion de TCP ~ \ cite {mathis1997macroscopic, Cardwell2016}. S'il y a un encombrement le long du chemin, il se stabilisera finalement sur le lien avec la bande passante du goulot d'étranglement.
Nous étendons cette hypothèse aux liens inter-AS et AS pour s'adapter à la granularité d'inférence précédemment discutée.

\ begin {supposition} {2} {parties communes} \ label {as: 1}
Si les mesures sur plusieurs trajets subissent un changement RTT partagé, les parties communes de ce chemin mesuré sont plus susceptibles d'être la cause.
\ end {hypothèse}
Il décrit une façon possible de satisfaire l'hypothèse ~ \ ref {as: 2} lorsque plusieurs mesures RTT avec des chemins d'intersection sont considérées.
C'est simplement un cas plus probable que d'avoir simultanément plusieurs parties éparses d'Internet provoquent un changement significatif. Nous utilisons cette hypothèse pour concevoir des ensembles spéciaux de mesures (métrique d'inférence) pour chaque nœud et un lien dans les graphiques de topologie pour tester leur responsabilité à chaque intervalle de temps de 10 minutes pour les événements de changement RTT.

Pour vérifier si un nœud (AS) $ n $ est la cause exclusive des modifications RTT partagées, nous
concevoir pour elle des ensembles de mesures (métrique d'inférence), dans lesquels le seul élément commun est le nœud lui-même. Si une majorité des mesures dans un tel ensemble expérimentent en même temps un changement de RTT, nous pouvons alors le localiser au nœud à l'étude, selon l'hypothèse ~ \ ref {as: 1}.

Après inférence de cause pour chaque nœud, nous pouvons exclure tous les liens avec l'un de ses deux nœuds inférés comme cause d'une enquête plus poussée, selon l'hypothèse ~ \ ref {as: 2}.

Ensuite, si un lien provoque effectivement un changement de RTT, nous nous attendons à ce qu'une majorité de mesures traversant ce lien subissent simultanément (dans un même intervalle de temps) le changement de RTT, condition nécessaire mais non suffisante pour la responsabilité de lien. En d'autres termes, en violant cette condition, le lien peut être exempté d'être cause du changement RTT.

Pour les liens restants après une exemption anticipée, leur responsabilité dépend des liens adjacents et non adjacents. Imaginez qu'un incident se produise au cœur d'Internet ou à un grand IXP, un large éventail de mesures traversant des liens périphériques, depuis la prochaine cause jusqu'à la limite de l'Internet, peut être potentiellement impacté. Pourtant, ces liens périphériques ne sont pas responsables du changement RTT.
Pour retracer la véritable cause du changement, différents critères sont nécessaires pour les liens dans différentes configurations topologiques.

Nous avons implémenté un outil de visualisation interactif pour inspecter le nombre normalisé d'événements et le résultat d'inférence de chaque lien sur la topologie au niveau AS révélée par les mesures de traceroute RIPE Atlas.
La figure ~ \ ref {fig: case_event_count} est un instantané de l'outil dans la vue de comptage d'événements normalisée.
Chaque cercle de la figure représente un AS ou un IXP appris à partir de mesures traceroute. Les sondes violet hébergent les sondes RIPE Atlas, les oranges sont des IXP, tandis que les vertes sont des AS de transit. Plus \ acp {FM} un lien a, plus la ligne correspondante est épaisse. À un intervalle de temps donné de 10 minutes (indiqué dans le coin supérieur gauche du graphique), plus le nombre d'événements de changement normalisé est grand, plus la couleur rouge sur le lien est profonde.

Conclusion

Cette thèse est développée autour d'une poursuite centralisée de \ textit {faisant un meilleur usage des diverses mesures de réseau dans l'ingénierie du trafic interdomaine sortant pour les AS stub}.

Nous avons souligné la nécessité de se concentrer sur les destinations les plus importantes.
Grâce à l'étude du dynamisme temporel des volumes par préfixe,
Nous sommes arrivés avec des méthodes simples qui sélectionnent efficacement les préfixes de destination avec des volumes de trafic importants.
L'évolutivité globale du système de mesure TE peut ainsi être améliorée, sans sacrifier une grande partie de la couverture de trafic.

Plus tard, nous nous sommes concentrés sur les mesures de latence.
Nous avons présenté et diagnostiqué certains problèmes de qualité des données précédemment sans surveillance.
Des lignes directrices pour atténuer leurs impacts sur le traitement des données et la sélection des routes ont été discutées.

Afin de mieux interpréter les mesures de performance, nous avons introduit l'analyse des points de changement dans le traitement des séries temporelles RTT.
Ces méthodes détectent des changements significatifs dans la performance du chemin et servent de déclencheur pour la resélection de l'itinéraire.
Pour permettre et encourager les efforts futurs, nous avons construit un cadre d'évaluation pour la détection de changement sur les mesures RTT Internet.

Enfin, avec l'aide de l'analyse des points de changement, nous avons été en mesure de qualifier le pourcentage d'un groupe de mesures qui a subi des changements RTT au même moment.
Nous avons en outre inféré les emplacements de réseau qui ont potentiellement provoqué ces changements.
Cette visibilité permet d'optimiser les itinéraires pour les préfixes que nous n'avons pas pu mesurer directement.
Afin de mieux illustrer le processus d'inférence et les causes identifiées, nous avons conçu des outils de visualisation interactifs pour tracer les métriques d'inférence et les résultats sur un graphe de topologie.


\end{otherlanguage}
\endgroup			

%\vfill
