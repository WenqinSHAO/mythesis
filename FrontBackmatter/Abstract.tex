%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\pdfbookmark[1]{Abstract}{Abstract}
\chapter*{Abstract}
As transit price continues to drop, mulithoming has now become a common practice among many medium and even small size networks. Yet, improving the transmission performance over multiple Internet paths remains challenging.
%Yet, how to improve the transmission performance through wise employment of multiple Internet paths remains challenging. 
One major difficulty comes from the current Internet routing protocol \acf{BGP}.
It is not performance-aware in propagating and choosing routes. 
On top of that, \ac{BGP} is not going to obsolete shortly.

To bypass the limitations of \ac{BGP}, some previous studies and industrial solutions suggest regular measurement of transmission performance over all available paths.
Then, the best routes are chosen for each destination considering not alone policies but as well measurements. That is the main idea of measurement-based \acf{TE}.
In transferring this idea into designs/systems that can cope with real network requirements, plenty of  issues are still left open.

First, measurement-based TE has to deal with the huge number of potential destinations.
This heavy measurement load is further multiplied by the number of available paths/providers.
Instead of covering the entire address space, it is more resource efficient to focus on several important destinations.
To verify the feasibility of that intuition, we studied working traffic traces from real networks.
The results showcased that most traffic is indeed concentrated on a small fraction of destinations.
Based on these findings, we devised simple methods to predict those `heavy-hitter' destinations.

Second, measurement-based TE requires insightful measurement interpretation.
In this work, we mainly cared about round-trip latency on Internet paths.
We first identified and diagnosed several data quality issues that were previously unattended.
Guidelines to mitigate their impacts were discussed.
Further, we tried to cluster latency time series with similar characters, e.g. overall variation level, a particular shape at a given moment.

We encountered difficulties in meaningfully clustering latency measurements. 
These difficulties led us to the detection of moments of significant changes for individual latency time series.
Moments of performance change can be regarded as a compact data representation of latency time series. They therefore have the potential to facilitate the grouping/clustering operation.
Ultimately, these moments are when route re-selection is potentially needed for the measured destinations.
Because otherwise traffic toward these destinations might suffer from avoidable performance degradation.
To that end, we applied \textit{changepoint analysis} methods to latency time series.
We devised an evaluation framework to quantify the robustness and sensitivity of diverse detection methods.
With the open-sourced evaluation method, we aimed at encouraging as well further efforts on methodological improvements.

Last but not the least, we tried to infer the network locations that are responsible for significant latency changes. This visibility allows performance-aware route selection for certain destinations that can not be measured directly.
When paths toward these destinations traverse change causes, we reasonably assume similar performance changes on these paths as well.
We since developed a series of inference procedures to attribute the cause of latency changes to \acf{AS} or inter-AS links.
Change detection methods previously studied were employed to first detect performance changes and then to group paths that underwent a same performance change.
To better illustrate the inference process and the identified causes for latency change, we built two interactive visualization tools to plot the results on a topology graph.

In this dissertation, we tackled some of the most pronounced challenges in measurement-based TE for interdomain routing. Contributions are brought to measurement scalability, interpretation of performance data and visibility on causes of performance changes. 
\vfill

\newpage

\begin{otherlanguage}{french}
\pdfbookmark[1]{Résumé}{Résumé}
\chapter*{Résumé}
Avec la baisse du prix de transit, multihoming a maintenant devenu une pratique courante parmi les réseaux de moyenne même petite taille.
Toutefois, il reste difficile de réellement améliorer la performance de transmission via ces multiple chemin désormais disponibles.
Une des difficultés est d’originaire du protocole de routage employé dans ce contexte : \acf{BGP}.
Le protocole ne prend pas en compte les éléments de performance lors de la sélection et la propagation des routes.
De plus, ce protocole va probablement continuer à dominer les routages d’Internet.

Pour pouvoir contourner les contraints du \ac{BGP}, des études dans le passé et des solutions industrielles suggèrent de mesurer régulièrement les multiples chemin Internet.
Puis, la meilleure route à chaque destination est sélectionnée selon les données de ces mesures. C’est ce que nous appelons l’ingénierie du trafic (TE) alimenté par la mesure.
En réalisant cette idée et satisfaisant les requis des vrais réseaux, pleine de problèmes sont laissés ouverts.

D’abord, un system comme tel doit pouvoir gérer énorme de destinations.
Cela pesse lourdement sur la fonctionnalité de mesure.
En plus, cette charge est multipliée par le nombre de chemins disponibles.
Au lieu de couvrir la totalité des destinations, il est clairement plus sage de se focaliser sur certains unes les plus importantes.
Afin de vérifier que ce soit faisable, nous avons étudié des vrais trafics sur les vrais réseaux à profils variés.
Le résultat montre qu’effectivement une grande partie de trafic se concentre sur une petite collection de destinations.
De plus, les trafics associés aux ces destinations sont relativement plus facile à prédire que le reste.
S’appuyant sur ces découverts, nous avons identifié des moyens simples mais efficaces à capter ces destinations d’importance.

Deuxièmement, les données récoltées par le system de mesure restent à être interpréter.
Dans cette thèse, nous nous occupons principalement la latence d’aller-retour comme l’indicateur de performance d’un chemin.
Nous avons commencé par identifier et analyser certains problèmes liés à la qualité de données.
Nous avons également discuté comment atténuer ces impacts.
En outre, nous avons essayé de grouper ensemble des séries temporelles de latence qui partage des traits similaires, par exemple vécus un changement au même moment.

En donnant des sens pratiques aux groups résulté, nous avons rencontré des difficultés.
Ils nous ont dirigé vers la détection de changement pour des séries temporelles de latence.
Les moments de changement significatif se peuvent être regardés comme un représentation compacte pour les données de performance. 
Ils nous facilitent ainsi l’opération de regroupage plus tard. 
Finalement, ces changements servent également comment déclencheur à la réévaluation des routes sélectionnées.
Car quand un changement de performance est survenu sur l’un des chemins mesurés, il indique soit une dégradation potentielle soit des espaces à l’amélioration. 
S’en rendant compte, nous avons mis en pratique des méthodes de \textit{changepoint analysis} sur des séries temporelles de latence.
Nous avons même conçu un mécanisme d’évaluation de la qualité de détection pour données de type latence Internet.
Les implémentations de cet outils et données labélisées sont rendu publique, dans l’objectif d’encourager les efforts à venir sur la méthodologie de détection.

Finalement, nous avons essayé d’inférer les endroits dans l’Internet qui sont susceptibles d’être la cause des changements de performance détectés.
Cette visibilité permet de réagir aux accidents pour certain destinations que nous n’arrivions pas à mesurer directement.
Quand certains chemins vers ces destinations traversent une cause de changement, il est probable que ces chemins non mesurés ont vécu le même changement que les autres mesurés.
Basant sur cette hypothèse, nous avons développé une sérié de logique qui attribue la cause de chaque changement de performance à un réseau sur le chemin ou un bout de lien entre deux réseaux.
Les méthodes de changpoint analysis étudiées plutôt nous aident d’abord à identifier les changements de performance sur chaque chemin mesuré, et puis à regrouper les chemins par les changements qu’ils ont vécu.
Pour mieux illustrer le processus et les résultats de l’inférence, nous avons développé des outils interactifs projetant les outputs de chaque étape sur une graphe de topologie.

Dans cette thèse, nous avons entrepris des défis les plus remarqués concernant l’ingénierie du trafic alimenté par la mesure dans routage Internet. Nous avons apporté des contributions sur la scalabilité, l’interprétation des données et la visibilité sur la cause de variation de performance.
\vfill
\end{otherlanguage}

\newpage

\begin{otherlanguage}{french}
\pdfbookmark[1]{Condensé du Manuscrit}{Condensé du Manuscrit}
\chapter*{Condensé du Manuscrit}

\section*{Introduction}
Internet est une collection de réseaux gérés individuellement.
Son système de gestion et de routage distribué lui permet de se développer rapidement.
Cependant, la distribution du trafic sous-optimale à partir d'une vue globale 
est également d'originaire de ce comportement distributé.
Ce problème se manifeste souvent par la congestion lorsqu'il existe encore de la capacité disponible.
De nombreux efforts ont donc été consacrés à une meilleure performance de la transmission,
en allégeant ou en évitant la congestion.

La congestion se produit sur un chemin Internet partagé par plusieurs flux lorsque la demande totale dépasse la capacité de liaison.
En évitant la concurrence vicieuse qui finit par bloquer tous les flux, le mécanisme de contrôle de la congestion de bout en bout joue un rôle important. 
Il améliore les performances de transmission de manière distribuée.
Il vise à 1) utiliser pleinement la bande passante tout en 
2) introduisant un minimum de delai de transmission supplémentaire (longueur de file d'attente courte) et en
3) assurant un partage équitable des ressources~\cite{Jacobson1988, mathis1997macroscopic, Cardwell2016}.

Les performances de transmission peuvent être encore améliorées avec une capacité de liaison suffisamment importante pour satisfaire la demande de tous les flux.
À cette fin, il est nécessaire de dimensionner régulièrement le réseau en fonction de la croissance des demandes de trafic~\cite{pioro2004routing}.
Pourtant, la construction d'infrastructures tout seul ne suffit pas.
Premièrement, le déploiement du réseau se déroule sur une période beaucoup plus longue que les fluctuations du trafic. 
Avant que la capacité supplémentaire ne soit déployée, certains liens peuvent devenir saturés alors que 
d'autres restent presque non-consommé en raison de la variation sporadique la demande de trafic. 
Deuxièmement, le surdimensionnement est coûteux, étant donné que les technologies futures réduiront considérablement le coût par unité de bande passante.

Par conséquent, des schémas de routage réactifs et flexibles sont nécessaires, complémentaires au dimensionnement du réseau.
Ils maximisent la capacité de réseaux qui peut être réellement utilisée.
Au sein d'un réseau (intra-domaine), l'administrateur peut en premier lieu estimer/modéliser la matrice de trafic qui traverse son réseau. 
Ensuite, chaque flux peut être divisé et cheminé sur plusieurs routes pour s'adapter au mieux à la capacité disponible~\cite{Xu2011, Jain2013}.
Parmi différents réseaux (inter-domaines), la marge d'amélioration des performances provient principalement de plusieurs chemins Internet 
entre les réseaux source et ceux de destination.
C'est parce que la capacité de bout en bout est potentiellement élargie avec des chemins Internet plus riches.
Une telle diversité de chemins peut déjà être obtenue via multihoming sous \acf{BGP}. 
Avec le multihoming, un réseau achète l'accès au reste de l'Internet via plusieurs fournisseurs.
De nombreuses propositions encouragent également la propagation de plusieurs chemins Internet, 
pour ne citer que quelques-un : BGP add-path~\cite{addpath}, MIRO~\cite{Xu2006}, NIRA~\cite{Yang2007}, YAMR~\cite{Ganichev2010}, Pathlet~\cite{Godfrey09}, IDRD~\cite{Misseri2013}, etc.
Cependant, dans le routage inter-domaine, chaque réseau n'a toujours pas la visibilité en dehors de son propre territoire, 
par exemple, la capacité d'une liaison distante et la demande de trafic concurrente  provenant d'autres réseaux sur ce lien.
Ceci est particulièrement vrai avec \ac{BGP}, le protocole de routage inter-domaine de facto qui ne va pas être obsolète prochainement.
Par conséquent, il n'est pas possible pour les réseaux actuels de déterminer quels chemins disponibles offrent les meilleures performances vers une destination donnée.
En d'autres termes, le défi est de savoir comment mieux utiliser la capacité Internet disponible avec un protocole agnostique de performance \ac{BGP}.
Nous entreprenons ce défi dans cette dissertation.

Une approche directe de rendre la décision de la route ayant conscience de la performance est la mesure. 
Par exemple, en connectant avec les autres réseaux, Facebook et Google utilisent des instruments intégrés dans leurs applications 
pour apprendre les aspects performances de bout en bout sur plusieurs chemins disponibles~\cite{Yap2017, Schlinker2017}.
Au fur et à mesure que le prix du transit diminue, le multi-homing devient plutôt une pratique courante dans de nombreux réseaux de petite et moyenne taille.
Ces réseaux ont également un besoin immédiat d'amélioration des performances, de sorte que leurs buinesses puissent survivre.

Malgré le besoin concret d'ingénierie du trafic inter-domaine basée sur des mesures, de nombreuses questions restent sans réponse ou partiellement traitées.
Un réseau typique peut communiquer régulièrement avec des destinations différentes $\sim$ 100k.
Mesurer continuellement la performance de toutes ces destinations est coûteux et n'est pas nécessaire.
Quelles sont les destinations les plus importantes? Est-ce que ces destinations changent au fil du temps? Comment les identifier?
En outre des mesures de volume de traffic, comment les mesures de performance doivent-elles être traitées? Ont-ils besoin de nettoyage?
Si oui, quels sont les problèmes potentiels de qualité des données? Quelles sont les origines de ces problèmes? 
Comment pouvons-nous mettre en valeur et atténuer leurs impacts sur la sélection des itinéraires?
En outre, afin de réagir dynamiquement aux changements de performance, 
comment détecter en premier lieu des changements significatifs dans les mesures de performance? 
Comment le faire sans paramètres codés en dur ou d'une manière ad hoc? Comment atteindre un niveau de robustesse acceptable?
Enfin, une fois qu'un changement de performance est détecté, comment pouvons-nous en savoir plus sur les aspects réseau? 
Où cela arrive-t-il? Cela peut-il avoir un impact sur d'autres chemins Internet actuellement utilisés?
Dans cette thèse, nous cherchons à explorer les réponses aux questions posées ci-dessus, 
afin que la fabrication d'un système TE basé sur des mesures avance dans ces aspects: 
scalabilité du system de mesure, interprétation des données de performance et visibilité des causes de changement de performance.

\section*{Le context}
Nous mettons en scène les travaux de cette thèse sous BGP, tout en réalisant pleinement \ac{LISP}, \ac{SDN}, etc. sont des pistes de recherche prometteuses.
C'est parce que BGP sera encore le protocole de routage \textit {de facto} d'Internet dans un avenir prévisible.
Et le déploiement d'un nouveau mécanisme de routage doit être incrémentiel.
Avant la prédominance de tout ce qui n'est pas BGP, BGP est ce qu'une majorité d'\acf{AS} doit vivre avec.
Il y a donc des besoins immédiats d'amélioration.

Nous nous concentrons sur la TE pour trafic sortant dans cette thèse.
Car la TE entrante est intrinsèquement difficile sous BGP, en raison d'un manque de méthode efficace de guidage le trafic entrant.

Nous ciblons les \ac{AS} stub (potentiellement en multi-homing).
C'est parce que \acf{CP}, \acf{HP} et \acf{ISP}, étant les principaux types de réseaux parmi les AS stub, sont ceux qui ont le plus besoin de TE.
De plus, la re-sélection de chemin dynamique dans ces réseaux ne générera pas de problèmes de convergence de routes BGP sur l'ensemble de l'Internet.

Enfin, nous supposons que l'amélioration des performances de transmission est aujourd'hui la principale motivation pour la TE sortante.
L'acheminement du trafic sur Internet fait désormais face à moins de contraintes monétaires grâce à la baisse du prix de transit~\cite{transitprice, drpeering} 
et de la présence des \ac{IXP} de plus en plus dense dans le monde entier~\cite{pchixp}.
En revanche, en vu de la demande pour la diversité géographique et topologique de connexion~\cite{Chiu2015}, un défi de performance reste à relever.

Afin de réaliser réellement ce gain de performance provenant de multiples chemins d'Internet, 
une sélection de route dynamique basée sur des mesures de performance est requise, c'est-à-dire \textit{TE basé sur la mesure}.
\citet{Akella2008} a montré une preuve de concept d'un tel system.
Seulement 100 destinations sont émulées dans ce travail.
Ce nombre est beaucoup moins par rapport à l'échelle réelle qu'un AS stub peut faire face sur une base quotidienne.
Dans ce travail, le meilleur chemin pour chaque destination est choisi en fonction de \acf{EWMA} sur des mésures de \acf{RTT} dans le passé.
Les résultats montrent que la meilleure performance de transmission sur toutes les destinations est atteinte 
lorsque la décision d'itinéraire est prise selon uniquement la dernière mesure de \ac{RTT}.
Cependant, compte tenu de la nature bruissante des mesures \ac{RTT}, une telle approche simpliste peut conduire à des changements de chemin extrêmement fréquents.
En outre, traiter Internet comme une boîte noire pour les mesures de latence ne fournit pas une visibilité des événements de réseau sous-jacents, 
qui est utile et parfois nécessaire .
Ces événements de réseau, par ex. les changements de chemin et la congestion sont les causes réelles 
d'une dégradation significative des performances et ainsi les raisons du changement de route.

Afin de répondre aux préoccupations ci-dessus prononcées et de réduire l'écart entre le concept et un système qui fonctionne~\cite{b6},
nous étudions dans cette thèse multiples types de mesure dans des vrai réseaux et l'Internet lui même 
pour améliorer la scalabilité du system qui collecte des mesures, l'interprétation des mesures et la visibilité sur des événements réseaux ayant impact sur la performance.

Une plate-forme TE (pour traffic inter-domaine) basée sur la mesure a deux éléments essentiels.
Ils sont illustrés en noir sur la figure~\ref{fig:archi}: (i) le system qui mesure la performance des chemins utilisables et 
(ii) l'intelligence qui selectionne des chemins.
La performances de bout en bout est ainsi mesurée, plus précisément la latence aller-retour \acf{RTT}, 
sur toutes les chemins disponibles vers en semble de préfixe de destination donné.
Dans chaque préfixe de destination, quelques hôtes avec des ports ouverts, par ex. 80, 443, sont découverts puis utilisés comme destination de mesure.
Une fois alimenté par les mesures de performance, le moteur de décision choisit pour chaque destination les meilleurs chemins à chaque instant et les implémente sur les routeurs BGP.

\section*{La sélection de préfixes les plus importants}

Un réseau client ayant besoin de \acf{TE} inter-domaine est souvent de type \acf{ISP}, \acf{HP}, \acf{CP}.
Il envoie du trafic vers un large éventail de destinations, en général entre 10k à 100k de prefixes BGP.
Le système de mesure et de décision de chemin illustré sur la figure~\ref{fig:archi} fait donc face à un défi 
qui est de suivre et d'optimiser en temps réel les performances de transmission vers toutes ces destinations.
Cependant, il est bien connu que la plupart du volume du trafic est généralement concentré sur une petite partie des préfixes BGP~\cite{Fang1999, Feamster2003, Papagiannaki2005, Sarrar2012}.
Il est donc possible et raisonnable de se concentrer uniquement sur les préfixes de destination les plus importants, .

% \ marginpar {la proposition}
A cette fin, il faut prévoir quels préfixes correspondront aux volumes du trafic les plus importants dans un proche avenir.
Deux blocs fonctionnels supplémentaires sont ainsi ajoutés à la figure~\ref{fig:archi}): 
(iii) la collecte de statistiques sur le volume de trafic; 
(iv) la sélection de préfixe, qui identifie parmi l'ensemble des destinations celles les plus importantes (c'est-à-dire ceux ayant le volume le plus élevé dans un avenir prévisible) 
et communique l'ensemble de préfixes sélectionné aux composants qui effectuent les mesure de performance et décident les chemins.

% \ marginpar {challenges}
Deux raisons nous obligent à \textit{prédictivement} sélectionner des préfixes de volume important et 
à concevoir des mécanismes spécifiques pour cette tâche.
Tout d'abord, le volume de trafic par préfixe évolue avec le temps, 
de même que l'ensemble des préfixes qui représentant un volume important.
Walleriche et al.~\cite{Wallerich2006} ont montré que le classement de la bande passante des flux 
peut changer radicalement d'un moment à l'autre.
Afin de maintenir un ensemble de préfixes d'importance, 
il faut donc prévoir répétitivement le volume de trafic pour chaque préfixe.
À notre connaissance, aucune étude n'a fait l'objet d'une enquête approfondie 
sur l'évolution dans le temps du volume de trafic associé aux préfixes BGP.

Deuxièmement, en prévoyant le volume de trafic pour chaque préfixe individuel, des méthodes plus efficaces sont nécessaires.
Les modèles bien établis \acf{TSF} et \acf{ANN} ont déjà été utilisés dans la prédiction du trafic~\cite{Papagiannaki2005, Cortez2006, Otoshi2013}.
Ces travaux ciblaient le trafic inter-\acf{PoP} pour les tâches hors ligne, telles que le dimensionnement de réseau.
Ces modèles sont non seulement lourds en termes de calcul, 
mais ils nécessitent également des pré-traitements des données et du réglage des paramètres d'une manière trace par trace. 
Ces coûts rendent ces méthodes moins applicables dans le contexte de l'inter-domaine TE qui implique jusqu'à 100k préfixes. 
Par conséquent, des méthodes de prédiction moins complexes sont nécessaires.

Nous avons analysé dans cette partie les traces du trafic réel provenant de neuf réseaux différents situés dans cinq pays 
pour comprendre la distribution du volume de trafic associé aux préfixes BGP, ainsi que sa variation dans le temps.
Nous avons observé que les préfixes les plus importants (représentant le plus grand volume sur une semaine) 
sont généralement stables dans le temps, avec de légères variations autour de leur volume moyen par heure.
Sur la base de cette observation, nous avons proposé trois simples
% et resource-economic% GgX: Comment une métrique peut-elle demander des ressources? Son calcul fait mais pas la métrique tiself
métriques (également faciles à calculer) pour sélectionner de manière proactive les préfixes ayant un volume de trafic prévisible important.
Nous avons démontré que les métriques que nous avons proposées conduisent à une meilleure couverture des volumes par rapport aux solutions existantes.
De plus, nous avons évalué les performances de transmission pour les préfixes de destination sélectionnés en utilisant plusieurs fournisseurs de transit.
Nous avons également simulé un algorithme qui selectionne des routes dynamiquement dans le temps.
Les résultats ont montré que même avec un mécanisme assez basique, 
la performance RTT globale pourrait être améliorée de $20\%$ dans certains réseaux étudiés par rapport au meilleur fournisseur de transit disponible.

\section*{La qaulité des mesures}

À partir d'ici, notre étude se concentre sur les mesures de latence et de trajectoires.
Ces mesures sont disponibles sur les platesformes TE chez les clients, de même que les données de volume étudiées dans le chapitre~\ref{sec:pref_selec}.
Cependant, dans un souci de reproductibilité, nous avons décidé de passer aux mesures effectuées par RIPE Atlas, une plateforme de mesure mondiale offrant un accès ouvert aux données. 

\subsection*{La complétude des données}

En plus de la reproductibilité, la qualité des données est un autre aspect clé pour les recherches en métrologie.
Grâce à des études antérieures~\cite{Holterbach2015a, Bajpai2015}, il est maintenant connu que en case de RIPE Atlas, la charge a des impacts évidents sur la précision et l'ordonnancement des mesures.
Nous nous concentrons sur la complétude des données, un autre aspect de la qualité des mesures qui a reçu moins d'attention jusqu'ici. 
Des mesures manquantes peuvent entraîner diverses conséquences indésirables.
En dehors de l'élargissement de l'intervalle de confiance de l'inférence~\cite{Fontugne2016}, 
il nécessite en général des adaptations méthodologiques, par ex. dans l'analyse spectrale~\cite{Babu2010, Luckie2014, shao2016}, 
sinon l'estimation serait biaisée~\cite{Baraldi2010}.
% Il est donc important de s'interroger sur la nature des mesures manquantes.

Une raison évidente de l'absence de données est que la sonde RIPE Atlas ne fonctionne pas (ou pas correctement), par ex. éteinte~\cite{schedule}.
Tant qu'une sonde est alimentée, elle essaie de maintenir une connexion à un contrôleur pour soumettre les mesures et recevoir les allocations des tâches comme indiqué sur la figure~\ref{fig:ripe_atlas_archi}.
Par conséquent, l'activité de connexion de la sonde fournit une bonne indication de la disponibilité de la sonde et 
est utilisée dans les investigations menées par RIPE sur la stabilité du système d'exploitation de la sonde~\cite{1look, 2look, 3look}.

Afin de déduire l'existence possible d'autres causes, nous avons comparé les horodatages de mesure avec 
les moments où un sonde se connecte et se déconnecte du système de contrôleur d'Atlas.
Si les mesures manquantes coïncident avec la déconnexion de la sonde, 
il y a de fortes chances que la raison de cette manque est que la sonde soit dysfonctionnelle, par ex. éteinte.
Cependant, si les mesures sont perdues lorsque la sonde est bien connectée, 
il faut s'attendre à quelque chose d'anormal, au-delà du problème connu du système d'exploitation de la sonde.

Dans notre analyse couvrant un grand nombre de sondes sur un mois, seulement $60\%$ des sondes v3 Atlas ont des mesures complètes. 
D'environ $1/3$ des segments de manques semblent étroitement liés à la période déconnectée. 
Le problème de stabilité du système d'exploitation de la sonde pourrait avoir contribué à de tels manques, 
comme le suggère la distribution à queue lourde de la longueur des segments manques.

Cependant, $2/3$ des segments de manques restants se sont produits pendant que les sondes sont connectées.
La moitié d'entre eux ne durent pas plus de 2 datapoints et sont donc susceptibles d'être causés par des problèmes d'ordonnancement. 
Cependant, environ $25\%$ de cette catégorie dure longtemps ($\geq 1h$).

Nous avons signalé la découverte à l'équipe d'ingénierie de RIPE avec un cas spécifique qu'ils pourraient examiner.
La dernière réponse de l'équipe RIPE a confirmé que la cas que nous avons cité dans le rapport avait des problèmes de synchronisation de l'heure. 
Pour aider à faire avancer l'enquête, nous avons partagé avec l'équipe RIPE tous les segments de manque de données de longue durée que nous avons identifiés. 
Ces échanges peuvent être trouvés sur le forum RIPE Atlas à \url{https://www.ripe.net/participate/mail/forum/ripe-atlas}, avec le titre ``Actual measurement interval much larger than planned''.

Bien que le résultat final ne soit pas concluant ni révélateur en termes de mécanisme sous-jacent, cette étude a aidé à réaliser un problème concernant la complétude des données et à le traiter sérieusement.
Ce problème peut être évité ou largement atténué, si les sondes sont correctement choisies comme source de données de mesure.
Avec des données complètes et relativement complètes au fil du temps, de nombreuses étapes de nettoyage de données peu justifiables peuvent être évitées.

\subsection*{La variation supplémentaire dans les mésures de latence}

Dans la TE inter-domaine, la qaulité de mesure depend aussi du fait \textit{si la mesure RTT reflète principalement les caractéristiques des chemins AS}.

La fonction de sélection d'itinéraire dans la figure~\ref{fig:archi} repose sur les mesures de performance de chemin (plus de détails dans le chapitre~\ref{sec:cpt_rtt}).
Toutefois, les mesures RTT peuvent être ``polluées'' par des facteurs non liés au réseau, par exemple des problèmes locaux tels que la surcharge du processeur,
 ou des problèmes de réseau au niveau sub-AS non qui ainsi ne sont pas pertinent, par exemple la congestion locale du réseau de la destination.
Réagir à ces problèmes n'est pas l'objectif principal de TE dans l'inter-domaine, car ce dernier tout seul ne se suiffit pas.
Cependant, aucun de ces travaux antérieurs~\cite{Goldenberg2004, Akella2008} n'a réalisé l'importance de ce problème.

Ce problème de qualité des données soulève une série de questions:
\textit{si nous mesurons un même chemin AS avec différents hôtes dans le préfixe de la destination, 
à quoi ressembleront ces différentes séries temporelles RTT? 
Auront-ils des traits similaires? 
Si non, comment pouvons-nous choisir celles qui conviennent le mieux aux fins de TE dans l'inter-domaine?}
Nous essayons de répondre à ces questions en effectuant des regroupements sur un tel ensemble de séries temporelles de RTT.
Sans connaissance préalable ou hypothèse, l'étude vise à révéler automatiquement les structures inhérentes de ces séries temporelles de RTT.

Dans cette étude, nous avons analysé des séries temporelles RTT entre deux AS.
Nous avons découvert que ces séries temporelles de RTT recueillies dans cette étude démontrent diverses formes de variation, 
bien qu'un chemin d'AS en commun soit mesurée.
Il a confirmé que les mesures RTT doivent être ``nettoyée''.
Nous avons regroupé ces séries temporelles RTT en extrayant
plusieurs caractéristiques comme leur représentation.
Les clusters résultants ont réussi à séparer les traces bruyantes des traces lisses selon l'intuition humaine et l'expertise.
De plus, nous avons localisé l'emplacement qui cause la plupart des variations dans les mesures RTT de bout en bout,
en appliquant les méthodes de regroupement aux premiers sauts des mesures traceroute.
Nos résultats ont confirmé le bon sens que la plupart des variations proviennent du réseau d'accès.

\section*{Détecter les changements dans les séries temporelles de RTT}

Les mesures RTT interviennent dans TE inter-domaine basé sur la mesure à deux phases.
Premièrement, les mesures RTT révèlent les moments où la resélection de l'itinéraire est nécessaire. % sinon la performance de transmission peut subir une dégradation évitable.
Deuxièmement, les mesures RTT servent de matériel de prise de décision dans la sélection de la route. 
Nous nous reportons sur le délai mesuré, les coûts de transmission et les politiques de routage, etc., 
pour décider quel chemin/fournisseur de transit est le meilleur choix pour atteindre chaque destination.
Nous discutons dans cette partie l'emploi des mesures RTT pendant cette première phase.

Les moments où la re-sélection de route est nécessaire sont essentiellement lorsque 
la performances sur certains chemins AS changent.
Le défi de la détection de changement de performance provient principalement de deux aspects.
Premièrement, les mesures RTT sont bruyantes.
De nombreux facteurs le long du trajet mesuré peuvent contribuer aux variations du délai de bout en bout, 
par ex. fluctuation de la charge sur l'hôte final, l'arrivé soudaine de traffic en grand volume, etc.
Cela nécessite des méthodes de détection du changement qui tolèrent des bruits tel que des diviation de courte durée,
tout en restant sensible aux événements qui comptent vraiment, tels que la congestion persistante.
Deuxièmement, les caractéristiques de latence sur les différents chemins peuvent se différer beaucoup.
Il est donc souhaitable de détecter les changements pour ces séries temporelles 
sans emploi de paramètres qui dépendant du chaqu chemin/destination.
Beaucoup de pratiques courantes ne satisfont pes les exigences énumérées ci-dessus.

% Les changements de chemin et l'encombrement sont connus pour être les principales raisons des changements RTT.
Il est généralement admis que les changements de routage inter-domaines ont un impact important sur le niveau de RTT.
Pucha et al.~\cite{Pucha2007} ont montré que les changements de routage inter-domaines 
entraînent une plus grande variation sur le médiane de RTT que les changements intra-domaine.
Rimondini et al.~\cite{Rimondini2014} ont confirmé que $72.5\%$ des changements de route BGP 
dans leur étude sont associés aux changements RTT.
%% Mesure de RIPE Atlas et RIPE RIS en 2013, seulement 55 AS sont considérés.
Des observations similaires ont été faites dans un grand \ac{CDN}, 
où les changements de routage inter-domaine sont responsables de plus de $40\%$ de dégradation de l'expérience utilisateur sévère~\cite{Zhu2012}.

Les événements intra-domaines ne sont pas moins importants. 
Pucha et al.~\cite{Pucha2007} ont découvert que les changements de chemin intra-domaine peuvent provoquer 
des changements RTT d'amplitude comparable à ceux inter-domaine.
En outre, ils ont souligné que ce sont les changements de chemin intra-domaine, et non la congestion, 
qui sont responsables de la majorité ($86\%$) des changements de RTT. % au lieu de la congestion.
Une découverte différente a cependant été faite par Schwartz et al.~\cite{Schwartz2010}. 
Ils ont observé que la plupart des variations RTT se situaient plutôt sur les chemins (c'est-à-dire en raison de la congestion) 
que parmi les chemins (c'est-à-dire en raison des changements de chemin).

Les conflits dans les travaux précédents pourraient être causés par les différents emplacements d'où les mesures ont été lancées.
Par exemple, Chandrasekaran et al.~\cite{Chandrasekaran} ont observé que les changements de chemin d'AS 
n'ont qu'un impact marginal sur RTT dans le noyau d'Internet. 
Cependant ces travaux précédents~\cite{Pucha2007, Schwartz2010} incluent aussi des réseaux d'accès.
Les résultats pourraient aussi changer avec le temps. 
Par exemple, la topologie Internet ``aplatie'', la quantité croissante de trafic dans les CDN au cours de la dernière décennie~\cite{Labovitz2011, Roughan2011}
pourrait avoir modifié les caractéristiques du changement de chemin et aussi de la congestion, et par conséquent, leur impact sur RTT.

En gardant cela à l'esprit, nous aimerions souligner les efforts sur les méthodes et les outils.
Ils permettent une analyse itérative dans le temps, 
au-delà de l'observation ou de l'analyse ponctuelle sur un ensemble de données spécifique.

La discussion et la découverte des travaux précédents sont éclairantes, 
mais leurs méthodes de traitement de mesure RTT peuvent difficilement être appliquées à la TE intra-domaine.
Dans~\cite{Pucha2007, Schwartz2010, Chandrasekaran},
les mesures RTT sont d'abord groupées par des chemins sous-jacents;
l'impact des changements de route sur RTT est ensuite estimé par la comparaison des statistiques de RTT associées, par ex. des centiles.
Cependant, dans un système TE  esquissé dans la figure~\ref{fig:archi}, 
les RTT sont mesurés avec une fréquence plus élevée que les chemins.
Ainsi, on n'est pas tout le temps sûr sur le chemin emprunté par une mésure RTT à un moment donnée. 
Les raisons sous-jacentes sont triples.
Premièrement, les mesures RTT sont en général moins coûteuses.
Compte tenu du nombre potentiel de destinations à surveiller (voir section~\ref {sec:pref_selec}), 
les mesures de chemin sont mieux limitées.
Deuxièmement, un RTT plus petit est l'objectif de TE, nous avons donc l'incitation à suivre de près son évolution. 
Cependant, le chemin est juste un des résultats de l'optimisation.
Troisièmement, les changements RTT se produisent généralement plus fréquemment que les changements de chemin.
Une raison importante est la congestion.
Le regroupement des mesures de RTT par des changements de route ne peut pas éclairer la présence de tels événements.
Par conséquent, nous devons explorer des méthodes qui permettent d'identifier les changements RTT inhérents, 
au lieu de s'appuyer sur des mesures externes telles que les changements de chemin pour décrire la variation des performances de transmission.

Parmi les études approfondies sur les méthodes de détection des changements et leurs applications dans divers domaines~\cite{Zhang2007, Reeves2007, Yu2008},
Rimondini et al.~\cite{Rimondini2014} sont parmi les premiers à utiliser la détection de changement dans l'analyse de mesure de RTT.
Cependant, ils ont réglé la sensibilité de détection de telle sorte que 
les changements détectés correspondent le mieux aux changements de route BGP vers le préfixe de destination mesuré 
parmi d'autres préfixes choisis au hasard.
Cette approche risque d'ignorer les changements RTT dus aux changements de chemin dans intra-domaine et à la congestion.
De plus, un tel réglage est potentiellement nécessaire pour chaque destination individuelle, donc difficile à mettre à l'échelle.
Pour obtenir une approche plus générale et découplée des mesures de chemin, 
nous proposons dans cette partie un cadre d'évaluation pour la sélection et l'étalonnage des méthodes de détection des changements 
dans leur applications sur les mesures RTT.

Quelle méthode (parmi les nombreuses propositions existantes) est la plus appropriée 
pour les séries temporelles de RTT dans l'Internet n'est toujours pas prononcée.
De plus, de nombreuses méthodes de détection de changement sont paramétriques.
Identifier les meilleurs paramètres pour les entrées de type RTT reste aussi obsure.
L'absence d'un cadre d'évaluation est un problème fondamental pour résoudre les problèmes susmentionnés.

Un cadre d'évaluation quantifie la performance d'une certaine méthode de détection sur un ensemble de données de référence.
Avec l'évaluation quantifiée, différents paramètres d'une même méthode ou différentes méthodes peuvent être comparés et réglés 
afin de fournir les meilleurs résultats de détection.
Naturellement, un cadre d'évaluation devrait être composé de deux parties: 
1) un ensemble de données de ``vérité terrain'', 2) une méthode de notation.

Cet ensemble de données de ``vérité terrain'' n'est pas seulement un ensemble de séries temporelles RTT 
représentatives des caractères de latence sur Internet.
Il devrait aussi porter des étiquettes indiquant les moments de changement.
Nous ne sommes pas au courant d'un tel ensemble de données qui soit publiquement disponible à ce jour.
% Nous avons étiqueté manuellement 50 séries temporelles réelles RTT de RIPE Atlas contenant 408 087 mesures RTT.
% Les détails sont donnés dans la section ~ \ ref {sec:label}.
Nous expliquons dans la section~\ref{sec:label} comment nous le construisons avec beaucoup de soin.
Quant à la méthode de notation, elle quantifie la similarité/différence entre la ``vérité terrain'' 
et les points de changement détectés par les méthodes.
Nous expliquons dans la section~\ref{sec:score} que la classification classique vrai/faux positif est trop rigide 
pour l'étiquetage manuel et la détection de changement dans les séries temporelles de RTT.
Nous explorons et relevons les défis de la comparaison entre deux ensembles d'horodatages avec une tolérance de décalage temporel.

Avec le cadre d'évaluation prêt, il ouvre la porte à l'exploration de la méthode de détection de changement 
les plus performants pour les mesures RTT.
Pour la famille de détection présentée dans la section~\ref{sec:cpt}, 
deux principaux paramètres doivent être définis: la pénalité et la fonction de coût (qui depend de l'hypothèse de la distribution).
Nous considérons la combinaison entre tous les critères d'information introduits (AIC, BIC, MBIC et Hannan-Quinn), 
et tous les types de distribution supportés (Gaussiane, Poisson, Exponentiel et Gamma), y compris l'approche non-paramétrique basée sur la distribution empirique.

Avec quelques tests préliminaires, nous avons rapidement réalisé que la détection avec 
la distribution normale tend à être sur-sensible, 
sous tous les configuration possibles de pénalité.
Beaucoup de variations de courte durées et insignifiants au term d'amplitude sont marqués comme des changements.
C'est parce que la moyenne et la variance de la distribution normale sont indépendamment contrôlées par deux paramètres distincts, 
ce qui augmente les chances de s'adapter aux changements subtils.
D'un autre côté, les distributions exponentielle, Gamma et de Poisson sont trop engourdies.
La moyenne et la variance de Poisson et de la distribution exponentielle sont couplées par un paramètre,
qui restreint leur flexibilité d'ajustement~\footnote{Poisson, mean = variance = $\lambda$; exponentielle, moyenne / variance = $\lambda$, moyenne = $1/\lambda$.}.
La distribution gamma est confrontée au même problème, mais avec une histoire plus compliquée.
Une distribution gamma peut être décrite par deux paramètres $\alpha$ et $\beta$: mean = $\frac{\alpha}{\beta}$, variance = $\frac{mean}{\beta}$.
\cite{Killick2013a}, l'implémentation que nous utilisons, nécessite une entrée \textit{a priori} pour $\alpha$, qui détermine en fait la sensibilité globale.
Seul $\beta$ est ajusté pour la détection de changement.
Avec un plus grand $\alpha$, un $\beta$ plus grand est nécessaire pour maintenir la même estimation moyenne pour un segment donné.
Une moyenne fixe avec un plus grand $\beta$ impose une plus petite tolérance de variation, donc plus susceptible de diviser le segment donné en raison de changements de variance plus petits.
En bref, un plus grand $\alpha$ conduit à une détection plus sensible.
L'option par défaut définit $\alpha$ à 1, ce qui dégénère la distribution Gamma en distribution exponentielle.
Nous avons également essayé $\alpha$ de 1 à 100, avec l'étape égale à 1.
Aucun d'entre eux ne surpasse les meilleurs paramètres affichés plus tard.
Nous ne considérons donc plus la distribution Gamma.

En supposant une distribution exponentielle et de Poisson, 
nous remarquons que le niveau moyen d'une série temporelles de RTT décide d'une certaine manière la tolérance de variation.
Par exemple, pour un chemin incluant des liaisons transpacifiques, nous nous attendons à un RTT minimum supérieur à $80msec$.
Dans ce cas, la distribution de Poisson correspondante pourrait facilement tolérer des déviations RTT de $20msec$, 
ce qui est déjà non négligeable.
Cependant, le fait d'avoir une moyenne et une variance couplées peut aussi être une caractéristique souhaitable.
Nous avons observé au cours de l'étiquetage que le niveau d'un segment RTT et sa variance sont souvent positivement liés au cours des périodes de congestion.

Pour tirer parti de la caractéristique décrite ci-dessus et augmenter la sensibilité de détection, 
nous proposons pour la distribution exponentielle et de Poisson une \textit{transformation de données}: 
d'abord soustraire la série temporelle de RTT par sa valeur minimum (baseline) pour abaisser son niveau global; 
les changements sont ensuite détectées.
Ce paramètre est noté \texttt{cpt\_poisson} et \texttt{cpt\_exp} respectivement.
Pour l'intérêt de comparaison, nous considérons également la distribution de Poisson \textbf{sans transformation de données} 
et nous l'indiquons comme \texttt{cpt\_poisson\_naive}.
La distribution normale \texttt{cpt\_normal} et l'approche non-paramétrique \texttt{cpt\_np} 
sont appliquées directement sur les séries temporelles initiales.

Toutes les combinaisons entre les types de distribution et les choix de pénalité sont evaluées.
Pour chaque type de distribution, nous montrons seulement son paramètre de pénalité le plus performant en termes de score $F_2$ pondéré dans la figure~\ref {fig_eval_eval}.

Plus de $75\%$ de changements, en termes de poids, peuvent être détectés 
pour plus de la moitié des séries temporelles avec peu n'importe quel distribution.
Tous ces types de distribution ont montré une meilleure performance en considerant le $F_2$ pondéré que le $F_2$ classique, 
indiquant que certains changement non-détectés sont en effet de peu d'importance opérationnelle.
Cependant, il semble avoir un grand espace d'améliorations.
Des efforts sont particulièrement nécessaires pour augmenter la précision de detection.

La précision de \texttt{cpt\_normal} est particulièrement mauvaise.
Cela confirme que \texttt{cpt\_normal} est en effet sur-sensible sur les données de type RTT.
Au contraire, le rappel de \texttt{cpt\_normal} est remarquable parmi tous les candidats.
Cependant, ses scores $F_2$ sont les plus faibles parmi tous les candidats.
La pauvre performance globale de la détection souligne l'importance de trouver un juste équilibre entre la sensibilité et la pertinence.
Pour les autres méthodes, leurs performances sont relativement proches.
Par rapport à \texttt{cpt\_poisson\_naive} (sans transformation de données), 
\texttt{cpt\_poisson} obtient un rappel plus élevé sans sacrifier de façon évidente la précision.
Par conséquent, \texttt{cpt\_poisson} présente un léger avantage sur les performances globales.
En fait, sans transformation de données, en supposant la distribution exponentielle ne détecte 
aucun changement pour une grande partie des séries temporelles dans l'ensemble de données de vérité terrain.
Ce sont toutes des preuves que la transformation de données proposée améliore 
la performances de détection pour la distribution de Poisson et exponentielle.

Nous détectons aussi les changements de chemin rencontrés par les mesures RTT collectées.
Les changements de chemin de niveau AS et IP sont pris en compte.
Ils sont connus pour avoir un impact potentiel sur RTT.
Le but de la détection de changement de chemin n'est pas de répéter des études précédentes,
tel que quel type de changement de chemin contribue le plus au changement RTT.
Cela aide plutôt à améliorer la compréhension de la détection de changements pour les mesures RTT.

Le tableau~\ref{tab:corr_overview} détaille le nombre de correspondances entre les changements de chemin et ceux de RTT.
Chaque cellule indique le nombre de correspondances entre la ligne (type de changement de chemin) et 
la colonne (méthode de détection de changement RTT).
La dernière colonne contient le nombre total de changements de chemins de chaque type.
De même, la dernière ligne fournit le nombre total de changements RTT détectés par les deux méthodes.

La fraction des changements de chemin d'AS correspondant aux changements de RTT dans cet étude 
est beaucoup plus faible que ce taux de $72.5\%$ dans~\cite{Rimondini2014}.
Il semble que les changements de chemin AS ont un impact moins significatif sur RTT que la compréhension précédente.
Y a-t-il quelque chose de particulier dans nos données ou nos méthodes?
De plus, le nombre de changements de chemin d'AS correspondant à un changement de RTT par \texttt{cpt\_np} 
n'est que d'une moitié de celui par \texttt{cpt\_possion}. Pourquoi?
Tous ces phénomènes sont très intrigants.
Nous explorons les raisons sous-jacentes dans la section~\ref{sec:corr}.
Dans ce condensé, nous expliquons uniquement une de ces observations: 
pourquoi il y a une grande partie de changement RTT correspondent à aucun changements de chemin.

D'abord, nous n'avons pas été en mesure de mesurer le chemin de reoutr avec RIPE Atlas.
Par conséquent, il est impossible de détecter les changements de chemin sur cette partie-là.
Cependant, ces changements de chemin pourraient avoir contribué aux changements de RTT.
Notamment dans le contexte du routage inter-domaines où les chemins dans les deux sont souvent asymétriques.
Cela implique que les changements RTT provoqués par les changements de chemin sur le sens de retour 
sont probablement différents de ceux provoqués par les changements de chemin sur le sens d'aller.

Deuxièmement, la congestion.
La congestion peut être indépendante des changements de chemin et causer des variations significatives sur RTT.
La figure~\ref{fig:case_26328} donne un exemple typique de changements RTT probablement causés par la congestion.
Il y a trois augmentations transitoires de RTT qui peuvent être visuellement remarquées dans la sériee temporelle illustrée.
Nous disons que les deux derniers sont probablement de la congestion.
Premièrement, ils ne correspondent à aucun changement de chemin, au moins sur le sens d'aller.
Deuxièmement, ces augmentations sont probablement causées par le remplissage des files d'attente le long du chemin.
Parce que, les valuers RTT ne sont pas ``plates''.
Sur un chemin légèrement chargé, nous nous attendons à des mesures RTT relativement constantes.
C'est parce que les files d'attente sont presque vides, donc pas de place pour la variation de délai.
La valeur de RTT est dominée par la latence de propagation.
Cependant, les variations de RTT à l'intérieur de la bosse est 
probablement une manifestation de l'évolution de la demande de trafic, et comment ce dernier change la longueur des files d'atteinte.
Les deux bosses/congestion s'écartent de la value de base (la latence de propagation) et durent plusieurs heures.
Ils ont donc un impact significatif sur les performances de transmission.
Nous les avons détectés avec succès avec les méthodes de détection de changement étudiés dans cette thèse.
Cependant, une telle détection n'est pas possible avec la méthode précédemment proposée~\cite{Luckie2014}.
Il effectue une analyse spectrale sur les séries temporelles de RTT pour identifier des congestions périodiques.
Une telle congestion persistante est normalement due au manque de capacité du réseau.
Alors, la congestion transitoire dans la figure~\ref {fig:case_26328} est plus probablement causée 
par la variation de trafic soudaine.
La TE basé sur la mesure vise à éviter les deux types de congestion 
lorsqu'il existe des chemins alternatifs avec la capacité suiffisante.

Troisièmement, la détection sur-sensible.
Si nous supposons hardiment que les changements de chemin sur le sens de retour provoquent 
une quantité comparable de changements de RTT comme le font les changements de chemin sur le sens d'aller, 
il y a encore beaucoup de changements RTT non appariés.
Certains d'entre eux pourraient être effectivement attribués à la congestion, comme expliqué ci-dessus.
Les modifications RTT non appariées restantes sont manifestement le résultat d'une détection trop sensible.
Nous relevons,  à partir d'une vue macroscopique dans la section~\ref{sec:cpt_trace} et la section~\ref {sec:as_match_diff}, 
que \texttt{cpt\_poisson} a tendance à surestimer le nombre de changement lorsque la série temporelle de RTT est bruyante.
Des exemples individuels sont données dans la figure~\ref{fig:case_sensitivity} pour illustrer 
la nuance de sensibilité à partir d'une vue microscopique.
Dans la figure~\ref{fig:case_28002}, \texttt{cpt\_np} a détecté toute la congestion périodique de petite amplitude.
C'est en fait assez impressionnant, car ces changements sont à peine visibles pour les experts humains.
Les changements marqués par \texttt{cpt\_np} ont en effet mis en évidence leur présence, 
et les ont rendus plus faciles à remarquer visuellement.
Dans la figure~\ref{fig:case_26328}, les deux méthodes ont identifié les deux grandes bosses près de la fin de la série temporelle.
La différence est que\texttt{cpt\_poisson} a également marqué les changements de niveau intermédiaire.
Ces changements intermédiaires ne sont pas corrélés aux changements de chemin.
En plus de cela, ils sont également redondants en informant la congestion qui se produisait à ce moment-là.
La raison d'une telle sur-sensibilité était due à son incompétence  de l'ajustement de la sensibilité de détection en fonction du niveau de variance. 
Ce problème est exploré et expliqué dans la section~\ref{sec:over_sensitive}.

Pour résumer le travail de cette section, nous avons proposé un cadre d'évaluation pour la détection des changements sur les séries temporelles RTT.
Le cadre est robuste avec l'ensemble de données étiqueté manuellement et pondère les changements RTT en fonction de leur importance dans l'opération du réseau.
Nous avons en outre conçu une transformation de données adaptée aux mesures RTT pour améliorer la sensibilité de détection de certaines méthodes de détection.
Enfin, nous corrélons les changements RTT et path détectés en établissant une correspondance entre eux.
Nous avons étudié la distinction de sensibilité entre différentes méthodes de détection des changements.

\section*{Déduire l'emplacement responsable de changements RTT}
Cette idée provient d'abord de l'étude de cas dans la section~\ref{sec:ripe_case_study} 
sur les changements RTT partagés par plusieurs séries temporelles RTT traversant des différents chemins AS.
Nous avons réalisé que ces changements RTT ne sont pas exclusifs aux mesures sur un chemin Internet spécifique, 
mais impactent plutôt plusieurs séries temporelles RTT simultanément, comme le montre la figure~\ref {fig:rtt3d_mp_cls2}.
Optimiser le routage inter-domaine contre la cause de tels changements de RTT 
serait alors une approche plus fondamentale et plus efficace que de traiter chaque préfixe individuel et chaque chemin vers eux.

Afin de déduire l'emplacement des causes, une hypothèse raisonnable est que 
de tels changements RTT partagés sont plus probablement causés par les parties communes de ces chemins, 
au lieu d'être la conséquence d'une synchronisation parfaite entre plusieurs problèmes dispersés dans divers endroits.
Avec cela, il est alors possible d'affiner la portée des causes possibles avec des mesures 
ayant à la fois des parties communes et des parties divergentes.
Un exemple de jeu d'inférence est donné dans la figure~\ref{fig:chap5_toy_inference}.
Avec l'hypothèse, nous pouvons d'abord étendre la cause aux liens 1 et 4, aux nœuds 2 et 5.
Comme il y a une mesure sans changement de RTT, celui traversant lien 1 et le nœud 2.
lien 1 et le nœud 2 sont ainsi moins probable d'être la cause.
En consequence, le lien 4 et le nœud 5 sont alors plus susceptibles d'être la cause.
%Dans la section~\ref{sec:inference}, nous décrirons plus formellement les hypothèses et la logique d'inférence pour l'investigation des nœuds et des liens sous tous les modèles de topologie et distributions de mesures possibles.

Nous sommes intéressés à identifier l'endroit dans l'Internet, aussi précise que possible, 
qui est responsable des changements RTT détectés.
Ceux que nous avons en entrée sur la plates-formes TE chez les clients sont 
1) les mesures RTT provenant de sources multiples vers des destinations multiples pour les utilisations TE; 
2) les chemins AS sous-jacents pour ces mesures RTT.
Les sources de mesures sont les plates-formes clientes et 
les destinations sont les préfixes auxquels les clients envoient leur trafic.
La source des mesures peut être multiple si nous fusionnons des mesures provenant de plusieurs plates-formes clientes 
ou si le client a plusieurs sites avec différentes options de fournisseur.

La figure~\ref{fig:chap5_sys_design} décrit les composants pour l'inférence de la cause de changement de RTT. 
La détection de changement (section~\ref{sec:cpt_rtt}) transforme les séries temporelles de RTT en séquences d'evènement de change.
La construction de la topologie construit un graph pour les AS et les liaisons traversés par les mesures RTT.
Ce graphe de topologie est une étape intermédiaire dans la conception d'une métrique d'inférence 
pour chaque nœud et chaque lien présents dans la topologie. 
Comme on le voit sur la figure~\ref{fig:chap5_toy_inference}, le fait que si un nœud/lien est la cause du changement RTT
dépend non seulement des mesures qui le traversent, mais aussi de celles à coté. 
L'identification de tels ensembles de mesures pour chaque nœud/lien nécessite des connaissances sur la topologie. 
De plus, le graphe de topologie sert aussi à visualiser l'endroit des cause inférés.
La valeur exacte de ces métriques d'inférence à chaque instant est calculée à partir de séquences d'événements de changement RTT. 
Ensuite, l'inférence de cause est effectuée pour chaque nœud et chaque lien en fonction de la valeur de leurs métriques d'inférence.
% Les séquences d'événements de modification RTT instancient les métriques d'inférence sur lesquelles l'inférence de cause est effectuée.
La sortie de l'ensemble du système indique les liens et les noeuds responsables des changements RTT à un moment donné.

Afin d'initier l'inférence, nous avons fait deux hypothèses.
\begin{assumption}{1}{cause unique}
Pour chaque changement RTT détecté, il n'y a qu'une seule cause, nœud ou lien, sur le chemin mesuré.
\end{assumption}
C'est une hypothèse courante faite dans les études de congestion de TCP~\cite{mathis1997macroscopic, Cardwell2016}. 
S'il y a une congest le long du chemin, il se stabilisera finalement sur le lien avec la bande passante la plus faible.
Nous étendons cette hypothèse aux liens inter-AS et AS pour s'adapter à la granularité d'inférence.

\begin{assumption}{2}{parties communes}
Si les mesures sur plusieurs chemins subissent un changement RTT partagé, 
les parties communes de ce chemin mesuré sont plus susceptibles d'être la cause.
\end{assumption}
Il décrit une façon possible de satisfaire l'hypothèse précédente lorsque plusieurs mesures RTT avec des intersections sur leur chemins sont considérées.
C'est simplement un cas plus probable que d'avoir simultanément plusieurs parties éloignées dans l'Internet provoquent un changement significatif à la même instant. 
Nous utilisons cette hypothèse pour concevoir des ensembles de mesures spécifiques (métrique d'inférence) pour chaque nœud et chaque lien dans le graph de topologie.
Ensuit, nous examinons chaque lien et chaque nœud sur le graph à l'intervalle de 10 minutes.

Pour vérifier si un nœud (AS) est la cause exclusive d'un changement RTT partagées, nous
concevoir pour elle un ensembles de mesures (métrique d'inférence), dans lesquels le seul élément commun est le nœud lui-même. 
Si une majorité des mesures dans un tel ensemble vivre en même temps un changement de RTT, 
nous pouvons alors le localiser au nœud en question, selon l'hypothèse~\ref{as:1}.

Après inférence de cause pour chaque nœud, nous pouvons exclure tous les liens avec l'un de ses deux nœuds inférés comme cause, selon l'hypothèse~\ref{as:2}.
Ensuite, si un lien provoque effectivement un changement de RTT, 
nous nous attendons à ce qu'une majorité de mesures traversant ce lien subissent simultanément (dans un même intervalle de temps) un changement de RTT, 
condition nécessaire mais non suffisante pour la responsabilité de lien. 
En d'autres termes, en violant cette condition, le lien peut être exempté d'être cause du changement RTT.

Pour les liens restantes, leur responsabilité dépend des liens adjacents et non adjacents. 
Imaginez qu'un incident se produise au cœur d'Internet ou à un grand IXP, 
un large éventail de mesures traversant des liens périphériques peut être potentiellement impacté. 
Pourtant, les liens périphériques ne sont pas responsables du changement RTT.
Pour retracer la véritable cause du changement, différents critères sont nécessaires pour les liens dans différentes configurations topologiques.

Nous avons implémenté un outil de visualisation interactif pour inspecter le nombre normalisé d'événements de changement RTT 
et le résultat d'inférence de chaque lien/nœud sur le graph de topologie.
La figure~\ref{fig:case_event_count} est un capture d'écran de l'outil qui montre l'intensité de changement RTT sur chaque lien.

\section*{Conclusion}

Cette thèse est développée autour d'une poursuite de 
\textit{mieux utiliser les diverses mesures de réseau dans l'ingénierie du trafic sortant en inter-domaine pour les AS stub}.

Nous avons souligné la nécessité de se concentrer sur les destinations les plus importantes.
Grâce à l'étude du dynamisme temporel des volumes par préfixe BGP,
nous sommes arrivés avec des méthodes simples qui sélectionnent efficacement l
es préfixes de destination avec des volumes de trafic importants.
La scalabilité du système de mesure peut ainsi être améliorée.

Plus tard, nous nous sommes concentrés sur les mesures de latence.
Nous avons présenté et diagnostiqué certains problèmes de qualité des données.
Des lignes directrices pour atténuer leurs impacts sur le traitement des données et la sélection de route ont été discutées.

Afin de mieux interpréter les mesures de performance, 
nous avons introduit la detection de changement dans le traitement des séries temporelles RTT.
Ces méthodes détectent des changements significatifs sur la performance du chemin et 
servent de déclencheur pour la re-sélection de route.
Pour permettre et encourager les efforts futurs, nous avons construit un cadre d'évaluation 
sur la détection de changement pour les mesures RTT dans l'Internet.

Enfin, avec l'aide de la detection de changement, nous avons été en mesure de qualifier 
le pourcentage d'un groupe de mesures qui subissent des changements RTT au même moment.
Nous avons en outre inféré les endroits dans l'Internet qui ont potentiellement provoqué ces changements.
Cette visibilité permet d'optimiser le routage ver des préfixes que nous n'avons pas pu mesurer directement.
Afin de mieux illustrer le processus d'inférence et les causes identifiées, 
nous avons conçu des outils de visualisation interactifs afin de tracer les métriques d'inférence et 
aussi les résultats d'inférence sur un graphe de topologie au niveau AS.

\vfill

\end{otherlanguage}
\endgroup			

%\vfill
