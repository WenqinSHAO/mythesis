%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}

As transit price continues to drop, mulithoming has now become a common practice among many medium and even small size networks. Yet, improving the transmission performance over multiple Internet paths remains challenging.
%Yet, how to improve the transmission performance through wise employment of multiple Internet paths remains challenging. 
One major difficulty comes from the current Internet routing protocol \acf{BGP}.
It is not performance-aware in propagating and choosing routes. 
On top of that, \ac{BGP} is not going to obsolete shortly.

To bypass the limitations of \ac{BGP}, some previous studies and industrial solutions suggest regular measurement of transmission performance over all available paths.
Then, the best routes are chosen for each destination considering not alone policies but as well measurements. That is the main idea of measurement-based \acf{TE}.
In transferring this idea into designs/systems that can cope with real network requirements, plenty of  issues are still left open.

First, measurement-based TE has to deal with the huge number of potential destinations.
This heavy measurement load is further multiplied by the number of available paths/providers.
Instead of covering the entire address space, it is more resource efficient to focus on several important destinations.
To verify the feasibility of that intuition, we studied working traffic traces from real networks.
The results showcased that most traffic is indeed concentrated on a small fraction of destinations.
Based on these findings, we devised simple methods to predict those `heavy-hitter' destinations.

Second, measurement-based TE requires insightful measurement interpretation.
In this work, we mainly cared about round-trip latency on Internet paths.
We first identified and diagnosed several data quality issues that were previously unattended.
Guidelines to mitigate their impacts were discussed.
Further, we tried to cluster latency time series with similar characters, e.g. overall variation level, a particular shape at a given moment.

We encountered difficulties in meaningfully clustering latency measurements. 
These difficulties led us to the detection of moments of significant changes for individual latency time series.
Moments of performance change can be regarded as a compact data representation of latency time series. They therefore have the potential to facilitate the grouping/clustering operation.
Ultimately, these moments are when route re-selection is potentially needed for the measured destinations.
Because otherwise traffic toward these destinations might suffer from avoidable performance degradation.
To that end, we applied \textit{changepoint analysis} methods to latency time series.
We devised an evaluation framework to quantify the robustness and sensitivity of diverse detection methods.
With the open-sourced evaluation method, we aimed at encouraging as well further efforts on methodological improvements.

Last but not the least, we tried to infer the network locations that are responsible for significant latency changes. This visibility allows performance-aware route selection for certain destinations that can not be measured directly.
When paths toward these destinations traverse change causes, we reasonably assume similar performance changes on these paths as well.
We since developed a series of inference procedures to attribute the cause of latency changes to \acf{AS} or inter-AS links.
Change detection methods previously studied were employed to first detect performance changes and then to group paths that underwent a same performance change.
To better illustrate the inference process and the identified causes for latency change, we built two interactive visualization tools to plot the results on a topology graph.

In this dissertation, we tackled some of the most pronounced challenges in measurement-based TE for interdomain routing. Contributions are brought to measurement scalability, interpretation of performance data and visibility on causes of performance changes. 
\vfill

\newpage

\begin{otherlanguage}{french}
\pdfbookmark[1]{Résumé}{Résumé}
\chapter*{Résumé}
Avec la baisse du prix de transit, multihoming a maintenant devenu une pratique courante parmi les réseaux de moyenne même petite taille.
Toutefois, il reste difficile de réellement améliorer la performance de transmission via ces multiple chemin désormais disponibles.
Une des difficultés est d’originaire du protocole de routage employé dans ce contexte : \acf{BGP}.
Le protocole ne prend pas en compte les éléments de performance lors de la sélection et la propagation des routes.
De plus, ce protocole va probablement continuer à dominer les routages d’Internet.

Pour pouvoir contourner les contraints du \ac{BGP}, des études dans le passé et des solutions industrielles suggèrent de mesurer régulièrement les multiples chemin Internet.
Puis, la meilleure route à chaque destination est sélectionnée selon les données de ces mesures. C’est ce que nous appelons l’ingénierie du trafic (TE) alimenté par la mesure.
En réalisant cette idée et satisfaisant les requis des vrais réseaux, pleine de problèmes sont laissés ouverts.

D’abord, un system comme tel doit pouvoir gérer énorme de destinations.
Cela pesse lourdement sur la fonctionnalité de mesure.
En plus, cette charge est multipliée par le nombre de chemins disponibles.
Au lieu de couvrir la totalité des destinations, il est clairement plus sage de se focaliser sur certains unes les plus importantes.
Afin de vérifier que ce soit faisable, nous avons étudié des vrais trafics sur les vrais réseaux à profils variés.
Le résultat montre qu’effectivement une grande partie de trafic se concentre sur une petite collection de destinations.
De plus, les trafics associés aux ces destinations sont relativement plus facile à prédire que le reste.
S’appuyant sur ces découverts, nous avons identifié des moyens simples mais efficaces à capter ces destinations d’importance.

Deuxièmement, les données récoltées par le system de mesure restent à être interpréter.
Dans cette thèse, nous nous occupons principalement la latence d’aller-retour comme l’indicateur de performance d’un chemin.
Nous avons commencé par identifier et analyser certains problèmes liés à la qualité de données.
Nous avons également discuté comment atténuer ces impacts.
En outre, nous avons essayé de grouper ensemble des séries temporelles de latence qui partage des traits similaires, par exemple vécus un changement au même moment.

En donnant des sens pratiques aux groups résulté, nous avons rencontré des difficultés.
Ils nous ont dirigé vers la détection de changement pour des séries temporelles de latence.
Les moments de changement significatif se peuvent être regardés comme un représentation compacte pour les données de performance. 
Ils nous facilitent ainsi l’opération de regroupage plus tard. 
Finalement, ces changements servent également comment déclencheur à la réévaluation des routes sélectionnées.
Car quand un changement de performance est survenu sur l’un des chemins mesurés, il indique soit une dégradation potentielle soit des espaces à l’amélioration. 
S’en rendant compte, nous avons mis en pratique des méthodes de \textit{changepoint analysis} sur des séries temporelles de latence.
Nous avons même conçu un mécanisme d’évaluation de la qualité de détection pour données de type latence Internet.
Les implémentations de cet outils et données labélisées sont rendu publique, dans l’objectif d’encourager les efforts à venir sur la méthodologie de détection.

Finalement, nous avons essayé d’inférer les endroits dans l’Internet qui sont susceptibles d’être la cause des changements de performance détectés.
Cette visibilité permet de réagir aux accidents pour certain destinations que nous n’arrivions pas à mesurer directement.
Quand certains chemins vers ces destinations traversent une cause de changement, il est probable que ces chemins non mesurés ont vécu le même changement que les autres mesurés.
Basant sur cette hypothèse, nous avons développé une sérié de logique qui attribue la cause de chaque changement de performance à un réseau sur le chemin ou un bout de lien entre deux réseaux.
Les méthodes de changpoint analysis étudiées plutôt nous aident d’abord à identifier les changements de performance sur chaque chemin mesuré, et puis à regrouper les chemins par les changements qu’ils ont vécu.
Pour mieux illustrer le processus et les résultats de l’inférence, nous avons développé des outils interactifs projetant les outputs de chaque étape sur une graphe de topologie.

Dans cette thèse, nous avons entrepris des défis les plus remarqués concernant l’ingénierie du trafic alimenté par la mesure dans routage Internet. Nous avons apporté des contributions sur la scalabilité, l’interprétation des données et la visibilité sur la cause de variation de performance.

\end{otherlanguage}

\newpage

\begin{otherlanguage}{french}
\pdfbookmark[1]{Condensé du Manuscrit}{Condensé du Manuscrit}
\chapter*{Condensé du Manuscrit}
\section*{Introduction}
Internet est une collection de réseaux gérés individuellement.
Son système de gestion et de routage distribué lui permet de se développer rapidement.
Cependant, la distribution du trafic sous-optimale à partir d'une vue globale est d'originaire également de ce comportement distributé.
Ce problème se manifeste souvent par des congestion lorsqu'il existe encore de la capacité disponible.
De nombreux efforts ont donc été consacrés à une meilleure performance de la transmission, en allégeant ou en évitant la congestion.

La congestion se produit sur un chemin Internet partagé par plusieurs flux lorsque la demande totale dépasse la capacité de liaison.
En évitant la concurrence vicieuse qui finit par bloquer tous les flux, le mécanisme de contrôle de la congestion de bout en bout joue un rôle important. Il améliore les performances de transmission de manière distribuée.
Il vise à 1) utiliser pleinement la bande passante tout en 2) introduisant un minimum de retard de transmission supplémentaire (longueur de file d'attente courte) et 3) assurant un partage équitable des ressources ~\cite{Jacobson1988, mathis1997macroscopic, Cardwell2016}.

Les performances de transmission peuvent être encore améliorées avec une capacité de liaison suffisamment importante pour satisfaire la demande de tous les flux. À cette fin, il est nécessaire de dimensionner régulièrement le réseau en fonction de la croissance des demandes de trafic ~\cite {pioro2004routing}.
Pourtant, la construction d'infrastructures ne suffit pas. Premièrement, le déploiement du réseau se déroule sur une période beaucoup plus longue que les fluctuations du trafic. Avant que la capacité supplémentaire ne soit déployée, certains liens peuvent devenir saturés alors que d'autres restent presque inactifs en raison des changements dans la demande de trafic. Deuxièmement, le surdimensionnement est coûteux, étant donné que les technologies futures réduiront considérablement le coût par unité de bande passante.

Par conséquent, des schémas de routage réactifs et flexibles sont nécessaires, complémentaires au dimensionnement du réseau.
Ils maximisent la capacité utile réelle.
Au sein d'un réseau (intradomaine), l'administrateur peut en premier lieu estimer/modéliser la matrice de trafic qui traverse son réseau. 
Ensuite, chaque flux peut être divisé en plusieurs chemins pour s'adapter au mieux à la capacité disponible ~\cite {Xu2011, Jain2013}.
Parmi différents réseaux (interdomaines), la marge d'amélioration des performances provient principalement de plusieurs chemins Internet entre les réseaux source et ceux de destination.
C'est parce que la capacité de bout en bout est potentiellement élargie avec des chemins Internet plus riches.
Une telle diversité de chemins peut déjà être obtenue via multihoming sous current \acf{BGP}. Avec le multihoming, un réseau achète l'accès au reste de l'Internet via plusieurs fournisseurs.
De nombreuses autres propositions encouragent également la propagation de plusieurs chemins Internet, pour ne citer que quelques-un : BGP add-path~\cite{addpath}, MIRO~\cite{Xu2006}, NIRA~\ cité{Yang2007}, YAMR~\cite{Ganichev2010 }, Pathlet~\cite{Godfrey09}, IDRD~\cite{Misseri2013}, et etc.
Cependant, dans le routage interdomaine, chaque réseau n'a toujours pas la visibilité en dehors de son propre territoire, par exemple, la capacité d'une liaison distante et la demande de trafic concurrent d'autres réseaux sur ce lien.
Ceci est particulièrement vrai avec \ac{BGP}, le protocole de routage interdomaine de facto qui ne va pas être obsolète prochainement.
Par conséquent, il n'est pas possible pour les réseaux actuels de déterminer quels chemins disponibles offrent les meilleures performances vers une destination donnée.
En d'autres termes, le défi est de savoir comment mieux utiliser la capacité Internet disponible avec un protocole agnostique de performance \ac{BGP}.
Nous entreprenons ce défi dans cette dissertation.

Un moyen simple de rendre la décision de la route sensible aux performances est la mesure. Dans l'ingénierie de leur interconnection avec les autres réseaux, Facebook et Google utilisent des instruments intégrés dans leurs applications pour apprendre les performances de bout en bout sur plusieurs chemins disponibles ~\cite {Yap2017, Schlinker2017}.
Au fur et à mesure que le prix du transit diminue, le multi-homing devient plutôt une pratique courante dans de nombreux réseaux de petite et moyenne taille.
Ces réseaux ont également un besoin immédiat d'amélioration des performances, de sorte que leurs buinesses puissent survivre.

Malgré le besoin concret d'ingénierie du trafic interdomaine basée sur des mesures, de nombreuses questions restent sans réponse ou partiellement traitées.
Un réseau typique peut communiquer régulièrement avec des destinations différentes $\sim$ 100k.
Mesurer continuellement la performance de toutes ces destinations est coûteux et n'est pas nécessaire.
Quelles sont les destinations les plus importantes? Est-ce que ces destinations changent au fil du temps? Comment les identifier?
En outre des mesures de volume, comment les mesures de performance doivent-elles être traitées? Ont-ils besoin de nettoyage?
Si oui, quels sont les problèmes potentiels de qualité des données? Quelles sont les origines de ces problèmes? Comment pouvons-nous mettre en valeur et atténuer leurs impacts sur la sélection des itinéraires?
En outre, afin de réagir dynamiquement aux changements de performance, comment détecter en premier lieu des changements significatifs dans les mesures de performance? Comment le faire sans paramètres codés en dur ou ad hoc? Comment atteindre un niveau de robustesse acceptable?
Enfin, une fois qu'un changement de performance est détecté, comment pouvons-nous en savoir plus sur cet événement du point de vue du réseau? Où cela arrive-t-il? Cela peut-il avoir un impact sur d'autres chemins Internet actuellement utilisés?
Nous cherchons à explorer les réponses aux questions ci-dessus dans cette thèse, afin que la construction d'un système de sélection de routes basé sur des mesures progresse dans ces domaines: extensibilité du system de mesure, interprétation des données de performance et visibilité des causes de changement de performance.


\section*{Le context}
Nous mettons en scène les travaux de cette thèse sous BGP, tout en réalisant pleinement \ac{LISP}, \ac{SDN}, etc. sont des pistes de recherche prometteuses.
C'est parce que BGP sera encore le protocole de routage \textit {de facto} d'Internet dans un avenir prévisible.
Et le déploiement de tout nouveau mécanisme de routage doit être incrémentiel.
Avant la reprise de tout ce qui n'est pas BGP, BGP est ce qu'une majorité d'AS doit vivre avec.
Il y a donc des besoins immédiats d'amélioration.

Nous nous concentrons sur la TE pour trafic sortant dans cette thèse.
Car la TE entrante est intrinsèquement difficile avec le BGP, en raison d'un manque de méthode efficace de guidage du trafic.

Nous ciblons les \acf{AS} stub (potentiellement multi-hébergés).
C'est parce que \acf{CP}, \acf{HP} et \acf{ISP}, étant les principaux types de réseaux parmi les AS stub, sont ceux qui ont le plus besoin de TE.
De plus, la re-sélection de route dynamique dans ces réseaux ne générera pas de problèmes de convergence de routes BGP sur l'Internet.

Enfin, nous supposons que l'amélioration des performances de transmission est aujourd'hui la principale motivation pour la TE sortante.
L'acheminement du trafic sur Internet fait désormais face à moins de contraintes monétaires grâce à la baisse du prix de transit~\cite{transitprice, drpeering} et de la présence des \ac{IXP} de plus en plus dense dans le monde entier~\cite{pchixp}.
En revanche, en vu de la demande pour la diversité géographique et topologique de connexion~\cite {Chiu2015}, un défi de performance reste à relever.

Afin de réaliser réellement ce gain de performance provenant de multiples chemin d'Internet, une sélection de route dynamique basée sur des mesures de performance est requise, c'est-à-dire \textit{TE basé sur des mesures}.
\citet{Akella2008} a montré une demonstration d'un tel system de TE.
Seulement 100 destinations sont émulées dans ce travail.
Ce nombre est beaucoup moins par rapport à l'échelle réelle qu'un AS stub peut faire face sur une base quotidienne.
Dans ce travail, le meilleur itinéraire pour chaque destination est choisi en fonction de \ac{EWMA} sur des mésures de \acf {RTT} dans le passé.
Les résultats montrent que la meilleure performance de transmission sur toutes les destinations est atteinte lorsque la décision d'itinéraire est prise selon uniquement la dernière mesure.
Cependant, compte tenu de la nature bruissante des mesures \ac{RTT}, une telle approche simpliste peut conduire à des changements de chemin extrêmement fréquents.
En outre, traiter Internet comme une boîte noire pour les mesures de latence ne fournit pas une visibilité utile et parfois nécessaire des événements de réseau sous-jacents.
Ces événements de réseau, par ex. les changements de chemin et la congestion sont les causes réelles d'une dégradation significative des performances et ainsi les raisons du changement de route.

Afin de répondre aux préoccupations ci-dessus et de réduire l'écart entre le concept et un système de travail~\cite{b6},
Nous étudions dans cette thèse le volume de trafic, les mesures de latence sur les chemin Internet pour améliorer la scalabilité du system de mésure, l'interprétation des mesures et la visibilité des performances de l'interdomaine TE basé sur les mesures.

Une plate-forme interdomaine TE basée sur la mesure a deux éléments constitutifs essentiels.
Ils sont illustrés en noir sur la figure~\ref{fig:archi}: (i) mesure de la performance des chemins utilisables et (ii) décision d'itinéraire.
La plateforme mesure les performances de bout en bout, plus précisément la latence aller-retour \acf{RTT}, sur toutes les routes disponibles vers un préfixe de destination donné.
Dans chaque préfixe de destination, quelques hôtes avec des ports ouverts, par ex. 80, 443, sont découverts puis utilisés comme destination de mesure.
Une fois alimenté par les mesures de performance, le moteur de décision d'itinéraire choisit pour chaque destination les meilleurs itinéraires à chaque instant et les impose sur les routeurs de frontière BGP.

\section*{La sélection de préfixes les plus importants}

Un réseau client ayant besoin de \acf{TE} interdomain est souvent de type \acf{ISP}, \acf{HP}, \acf{CP}.
Il envoie du trafic vers un large éventail de destinations, en général entre 10k à 100k de prefixes BGP.
Le sous-système de mesure et de décision de route illustré sur la figure~\ref{fig:archi} fait donc face à un défi qui est de suivre et d'optimiser en temps réel les performances de transmission vers toutes ces destinations.
Cependant, il est bien connu que la plupart du volume du trafic est généralement concentré sur une petite partie des préfixes BGP~\cite {Fang1999, Feamster2003, Papagiannaki2005, Sarrar2012}.
Il est donc possible et raisonnable de se concentrer uniquement sur les préfixes de destination les plus importants.

% \ marginpar {la proposition}
A cette fin, il faut prévoir quels préfixes correspondront aux volumes de trafic les plus importants dans un proche avenir.
Deux blocs fonctionnels supplémentaires sont ainsi ajoutés à la conception du système dans la figure~\ref {fig:archi}): (iii) la collecte de statistiques sur le volume de trafic; (iv) la sélection de préfixe, qui identifie parmi l'ensemble des destinations celles les plus importantes (c'est-à-dire ceux ayant le volume le plus élevé dans un avenir prévisible) et communique l'ensemble de préfixes sélectionné aux sous-system de mesure et d'itinéraire.

% \ marginpar {challenges}
Deux raisons nous obligent à \textit{prédictivement} sélectionner des préfixes de volume important et concevoir des mécanismes spécifiques pour cette tâche.
Tout d'abord, le volume de trafic par préfixe évolue avec le temps, de même que l'ensemble des préfixes représentant un volume de trafic important.
Walleriche et al.~\cite{Wallerich2006} ont montré que le classement de la bande passante des flux peut changer radicalement d'un moment à l'autre.
Afin de maintenir un ensemble de préfixes d'importance, il faut donc prévoir à plusieurs reprises le volume de trafic pour chaque préfixe.
À notre connaissance, aucune étude n'a fait l'objet d'une enquête approfondie sur l'évolution dans le temps du volume de trafic associé aux préfixes BGP.

Deuxièmement, en prévoyant le volume de trafic pour chaque préfixe individuel, des méthodes plus efficaces sont nécessaires.
Les modèles bien établis \acf{TSF} et \acf{ANN} ont déjà été utilisés dans la prédiction du trafic~\cite{Papagiannaki2005, Cortez2006, Otoshi2013}.
Ces travaux ciblaient le trafic inter-acf {PoP} hautement agrégé pour les tâches hors ligne, telles que le dimensionnement de réseau.
Ces modèles sont non seulement lourds en termes de calcul, mais ils nécessitent également un pré-traitement des données et un réglage des paramètres d'une manière trace par trace. 
Ces coûts généraux rendent ces méthodes moins applicables dans le contexte de l'inter-domaine TE qui implique jusqu'à 100k préfixes. Par conséquent, des méthodes de prédiction moins complexes sont nécessaires.

Nous avons analysé dans cette partie les traces du trafic réel provenant de neuf réseaux différents situés dans cinq pays pour comprendre la distribution du volume de trafic associé aux préfixes BGP, ainsi que sa variation dans le temps.
Nous avons observé que les préfixes les plus importants (représentant le plus grand volume sur une semaine) sont généralement stables dans le temps, avec de légères variations horaires autour de leur volume moyen en heures.
Sur la base de cette observation, nous avons proposé trois simples
% et resource-economic% GgX: Comment une métrique peut-elle demander des ressources? Son calcul fait mais pas la métrique tiself
métriques (également faciles à calculer) pour sélectionner de manière proactive les préfixes ayant un volume de trafic prévisible important.
Nous avons démontré que les métriques que nous avons proposées conduisent à une meilleure couverture des volumes par rapport aux solutions existantes.
De plus, nous avons évalué les performances de transmission pour les préfixes de destination sélectionnés en utilisant plusieurs fournisseurs de transit.
Nous avons également simulé un algorithme de décision d'itinéraire dynamique.
Les résultats ont montré que même avec un mécanisme assez basique, la performance RTT globale pourrait être améliorée de 20\% par rapport au meilleur fournisseur de transit disponible dans certains réseaux étudiés.

\section*{La qaulité des mesures}

À partir d'ici, notre étude se concentre sur les mesures de latence et de trajectoires.
Ces mesures sont disponibles sur les platesformes TE chez les clients, de même que les données de volume étudiées dans le chapitre~\ref{sec:pref_selec}.
Cependant, dans un souci de reproductibilité, nous avons décidé de passer aux mesures effectuées par RIPE Atlas, une plateforme de mesure mondiale offrant un accès ouvert aux données. 

\subsection*{La complétude des données}

En plus de la reproductibilité, la qualité des données est un autre aspect clé pour les recherches en métrologie.
Grâce à des études antérieures~\cite{Holterbach2015a, Bajpai2015}, il est maintenant connu que en case de RIPE Atlas, la charge a des impacts évidents sur la précision et l'ordonnancement des mesures.
Nous nous concentrons sur la complétude des données, un autre aspect de la qualité des mesures qui a reçu moins d'attention jusqu'ici. 
Des mesures manquantes peuvent entraîner diverses conséquences indésirables.
En dehors de l'élargissement de l'intervalle de confiance de l'inférence~\cite{Fontugne2016}, 
il nécessite en général des adaptations méthodologiques, par ex. dans l'analyse spectrale~\cite{Babu2010, Luckie2014, shao2016}, 
sinon l'estimation serait biaisée~\cite {Baraldi2010}.
% Il est donc important de s'interroger sur la nature des mesures manquantes.

Une raison évidente de l'absence de données est que la sonde RIPE Atlas ne fonctionne pas (ou pas correctement), par ex. éteinte~\cite{schedule}.
Tant qu'une sonde est alimentée, elle essaie de maintenir une connexion à un contrôleur pour soumettre les mesures et recevoir les allocations des tâches comme indiqué sur la figure~\ref{fig:ripe_atlas_archi}.
Par conséquent, l'activité de connexion de la sonde fournit une bonne indication de la disponibilité de la sonde et est utilisée dans les investigations menées par RIPE sur la stabilité du système d'exploitation de la sonde~\cite{1look, 2look, 3look}.

Afin de déduire l'existence possible d'autres causes, nous avons comparé les horodatages de mesure avec les moments sonde se connecte et se déconnecte du système de contrôleur d'Atlas.
Si les mesures manquantes coïncident avec la déconnexion de la sonde, il y a de fortes chances que la raison de cette manque est que la sonde soit dysfonctionnelle, par ex. éteinte.
Cependant, si les mesures sont perdues alors que la sonde est bien connectée, il faut s'attendre à quelque chose d'anormal, au-delà du problème connu du système d'exploitation de la sonde.

Dans notre analyse couvrant un grand nombre de sondes sur un mois, seulement $60\%$ des sondes v3 Atlas ont des mesures complètes. 
D'environ $1/3$ des segments de manques semblent étroitement liés à la période déconnectée. 
Le problème de stabilité du système d'exploitation de la sonde pourrait avoir contribué à de tels manques, 
comme le suggère la distribution à queue lourde de la longueur des segments manques.

Cependant, $2/3$ des segments de manques restants se sont produits pendant que les sondes sont connectées.
La moitié d'entre eux ne durent pas plus de 2 datapoint et sont donc susceptibles d'être causés par des problèmes d'ordonnancement. 
Cependant, environ $25\%$ de cette catégorie dure longtemps ($\geq 1h$).

Nous avons signalé la découverte à l'équipe d'ingénierie de RIPE avec un cas spécifique qu'ils pourraient examiner.
La dernière réponse de l'équipe RIPE a confirmé que la cas que nous avons cité dans le rapport avait des problèmes de synchronisation de l'heure. 
Pour aider à faire avancer l'enquête, nous avons partagé avec l'équipe RIPE tous les segments de manque de données de longue durée que nous avons identifiés. 
Ces échanges peuvent être trouvés sur le forum RIPE Atlas à \url{https://www.ripe.net/participate/mail/forum/ripe-atlas}, avec le titre ``Actual measurement interval much larger than planned''.

Bien que le résultat final ne soit pas concluant ni révélateur en termes de mécanisme sous-jacent, cette étude a aidé à réaliser un problème concernant la complétude des données et à le traiter sérieusement.
Ce problème peut être évité ou largement atténué, si les sondes sont correctement choisies comme source de données de mesure.
Avec des données complètes et relativement complètes au fil du temps, de nombreuses étapes de nettoyage de données peu justifiables peuvent être évitées.

\subsection*{La variation supplémentaire dans les mésures de latence}

Un problème de qualité des données spécifique dans TE de l'interdomaine est \textit{si la mesure RTT reflète principalement les caractéristiques des chemins AS}.

La fonction de sélection d'itinéraire dans la figure~\ref{fig:archi} repose sur les mesures de performance de chemin (plus de détails dans le chapitre~\ref{sec:cpt_rtt}).
Toutefois, les mesures RTT peuvent être ``polluées'' par des facteurs non liés au réseau, par exemple des problèmes locaux tels que la surcharge du processeur,
 ou des problèmes de réseau de niveau sub-AS non représentatifs, par exemple la congestion locale du réseau de la destination.
Éviter ces problèmes n'est pas l'objectif principal de TE dans l'interdomaine, car ce dernier tout seul ne se suiffit pas.
Cependant, aucun de ces travaux antérieurs~\cite{Goldenberg2004, Akella2008} n'a réalisé l'importance de ce problème.

Ce problème de qualité des données soulève une série de questions:\textit{si nous mesurons un même chemin AS avec différents hôtes dans le préfixe de la destination, 
à quoi ressembleront ces différentes éries temporelles RTT? 
Auront-ils des traits similaires? 
Si non, comment pouvons-nous choisir celles qui conviennent le mieux aux fins de TE dans l'interdomaine?}
Nous essayons de répondre à ces questions en effectuant des regroupements sur un tel ensemble de séries temporelles de RTT.
Sans connaissance préalable ou hypothèse, l'étude vise à révéler automatiquement les structures inhérentes de ces séries temporelles de RTT.

Dans cette étude, nous avons analysé des séries temporelles RTT entre deux AS.
Nous avons découvert que les séries temporelles de RTT recueillies dans cette étude démontrent diverses formes de variation, 
bien qu'un chemin d'AS en commun soit mesurée.
Il a confirmé que les mesures RTT doivent être ``nettoyée''.
Nous avons regroupé ces séries temporelles RTT en extrayant
plusieurs caractéristiques comme leur représentation.
Les clusters résultants ont réussi à séparer les traces bruyantes des traces lisses selon l'intuition humaine et l'expertise.
De plus, nous avons localisé l'emplacement de la plupart des variations dans les mesures RTT de bout en bout en appliquant les méthodes de regroupement aux premiers sauts des mesures traceroute.
Nos résultats ont confirmé le bon sens que la plupart des variations proviennent du réseau d'accès.


\section*{Détecter les changements dans les séries temporelles de RTT}

Les mesures RTT interviennent dans TE d'interdomaine basé sur la mesure à deux phases.
Premièrement, les mesures RTT révèlent les moments où la resélection de l'itinéraire est nécessaire. % sinon la performance de transmission peut subir une dégradation évitable.
Deuxièmement, les mesures RTT servent de matériel de prise de décision dans la sélection de la route. 
Nous nous reportons sur le délai mesuré, les coûts de transmission et les politiques de routage, etc., 
pour décider quel chemin/fournisseur de transit est le meilleur choix pour atteindre chaque destination.
Nous discutons dans cette partie de l'utilisation des mesures RTT pendant la première phase.

Les moments où la re-sélection de route est nécessaire sont essentiellement lorsque les performances sur certains chemins AS changent.
Le défi de la détection de changement de performance provient principalement de deux aspects.
Premièrement, les mesures RTT sont bruyantes.
De nombreux facteurs le long du trajet mesuré peuvent contribuer aux variations du délai de bout en bout, 
par ex. fluctuation de la charge sur l'hôte final, circulation en rafale, etc.
Cela nécessite des méthodes de détection du changement pour tolérer des bruits tels que de courtes pointes de vie, tout en restant sensible aux événements qui comptent vraiment, tels que la congestion persistante.
Deuxièmement, les caractéristiques de retard sur différents chemins peuvent différer beaucoup.
Il est donc souhaitable de détecter les changements pour ces séries chronologiques sans paramètres dépendant du chemin / destination.
Beaucoup de pratiques courantes ne répondent pas aux exigences énumérées ci-dessus.
Dans cette section, nous résumons les études précédentes sur les variations RTT et leur relation avec les événements réseau.

% Les changements de chemin et l'encombrement sont connus pour être les principales raisons des changements RTT.
Il est généralement admis que les changements de routage inter-domaines ont un impact important sur le niveau de RTT.
Pucha et al.~\cite{Pucha2007} ont montré que les changements de routage inter-domaines entraînent une plus grande variation sur le médiane de RTT que les changements intra-domaine.
Rimondini et al.~\cite{Rimondini2014} ont confirmé que $72.5\%$ des changements de route BGP dans leur étude sont associés aux changements RTT.
%% Mesure de RIPE Atlas et RIPE RIS en 2013, seulement 55 AS sont considérés.
Des observations similaires ont été faites dans un grand \ac{CDN}, où les changements de routage inter-domaine sont responsables de plus de $40\%$ de dégradation de l'expérience utilisateur sévère~\cite{Zhu2012}.

Les événements intra-domaine ne sont pas moins importants. Pucha et al.~\cite{Pucha2007}ont découvert que les changements de chemin intra-domaine peuvent provoquer des changements RTT d'amplitude comparable à ceux d'inter-domaine.
En outre, ils ont souligné que ce sont les changements de chemin intra-domaine, et non la congestion, qui sont responsables de la majorité ($86\%$) des changements de RTT. % au lieu de la congestion.
Une découverte différente a cependant été faite par Schwartz et al.~\cite{Schwartz2010}. 
Ils ont observé que la plupart des variations RTT se situaient plutôt dans les chemins (c'est-à-dire en raison de la congestion) que parmi les chemins (c'est-à-dire en raison des changements de chemin).

Les conflits dans les travaux antérieurs pourraient être causés par la différence des emplacements d'où les mesures ont été lancées.
Par exemple, Chandrasekaran et al.~\cite{Chandrasekaran} ont observé que les changements de chemin d'AS n'ont qu'un impact marginal sur RTT dans le noyau d'Internet, 
alors que les travaux précédents ~\cite {Pucha2007, Schwartz2010} incluent aussi des réseaux d'accès.
Les résultats pourraient aussi changer avec le temps. 
Par exemple, la topologie Internet ``aplatie'', la quantité croissante de trafic dans les CDN au cours de la dernière décennie~\cite{Labovitz2011, Roughan2011}
pourrait avoir modifié les caractéristiques du changement de chemin et de la congestion, et par conséquent, leur impact sur RTT.

En gardant cela à l'esprit, nous aimerions souligner les efforts sur les méthodes et les outils.
Au-delà de l'observation ou de l'analyse ponctuelle sur un ensemble de données spécifique, 
ils permettent une analyse itérative dans le temps.

La discussion et la découverte des travaux précédents sont éclairantes, 
mais leurs méthodes de traitement de mesure RTT peuvent difficilement être appliquées à la TE dans intra-domaine.
Dans~\cite{Pucha2007, Schwartz2010, Chandrasekaran},
les mesures RTT sont d'abord groupées par des chemins sous-jacents;
l'impact des changements de route sur RTT est ensuite estimé par la comparaison des statistiques de RTT associées, par ex. des centiles.
Cependant, dans un système TE pratique esquissé dans la figure~\ref{fig:archi}, les RTT sont mesurés avec une fréquence plus élevée que les chemins.
Les raisons sous-jacentes sont triples.
Premièrement, les mesures RTT sont en général moins coûteuses.
Compte tenu du nombre potentiel de destinations à surveiller (voir section~\ref {sec:pref_selec}), les mesures de chemin sont mieux limitées.
Deuxièmement, un RTT plus petit est l'objectif de TE, nous avons donc l'incitation à suivre de près son évolution. 
Cependant, le chemin est juste le résultat de l'optimisation.
Troisièmement, les changements RTT se produisent généralement plus fréquemment que les changements de chemin.
Une raison importante est la congestion.
Le regroupement des mesures de RTT par des changements de route ne peut éclairer la présence de tels événements.
Par conséquent, nous devons explorer des méthodes qui permettent d'identifier les changements RTT inhérents, 
au lieu de s'appuyer sur des mesures externes telles que les changements de chemin pour décrire la variation des performances de transmission.

Parmi les études approfondies sur les méthodes de détection des changements et leurs applications dans divers domaines~\cite{Zhang2007, Reeves2007, Yu2008},
Rimondini et al.~\cite{Rimondini2014} sont parmi les premiers à utiliser la détection de changement dans l'analyse de mesure de RTT.
Cependant, ils ont réglé la sensibilité de détection de telle sorte que les changements détectés correspondent le mieux aux changements de route BGP vers le préfixe de destination mesuré parmi d'autres préfixes choisis au hasard.
Cette approche risque d'ignorer les changements RTT dus aux changements de chemin dans intra-domaine et à la congestion.
De plus, un tel réglage est potentiellement nécessaire pour chaque destination individuelle, donc difficile à mettre à l'échelle.
Pour obtenir une approche plus générale et découplée des mesures de route, 
nous proposons dans cette partie un cadre d'évaluation pour la sélection et l'étalonnage des méthodes de détection des changements pour les mesures RTT.

Quelle méthode (parmi la grande variété de ceux existants) est la plus appropriée pour les séries temporelles de RTT dans l'Internet n'est toujours pas indiqué.
De plus, de nombreuses méthodes de détection de changement sont paramétriques.
Identifier les meilleurs paramètres pour RTT reste aussi difficile.
L'absence d'un cadre d'évaluation est un problème fondamental pour résoudre les problèmes susmentionnés.

Un cadre d'évaluation quantifie la performance d'une certaine méthode de détection sur un ensemble de données de référence.
Avec l'évaluation quantifiée, différents paramètres d'une même méthode ou différentes méthodes peuvent être comparés et réglés pour fournir les meilleurs résultats de détection.
Naturellement, un cadre d'évaluation devrait être composé de deux parties: 
1) un ensemble de données de ``vérité terrain'', 2) une méthode de notation.

Cet ensemble de données de ``vérité terrain'' n'est pas seulement un ensemble de séries temporelles RTT représentatives des caractères de latence sur Internet.
Il devrait aussi porter des étiquettes indiquant les moments de changement.
Nous ne sommes pas au courant d'un tel ensemble de données qui soit publiquement disponible à ce jour.
% Nous avons étiqueté manuellement 50 séries temporelles réelles RTT de RIPE Atlas contenant 408 087 mesures RTT.
% Les détails sont donnés dans la section ~ \ ref {sec:label}.
Nous expliquons dans la section~\ref{sec:label} comment nous le construisons avec beaucoup de soin.

Quant à la méthode de notation, elle quantifie la similarité/différence entre la ``vérité terrain'' et les points de changement détectés par les méthodes.
Nous expliquons dans la section~\ref{sec:score} que la classification classique vrai/faux positif est trop rigide pour l'étiquetage manuel et la détection de changement dans les séries temporelles de RTT.
Nous explorons et relevons les défis de la comparaison entre deux ensembles d'horodatages avec une tolérance de décalage temporel.

Avec le cadre d'évaluation prêt, il ouvre la porte à l'exploration de la méthode de détection des points de changement les plus performants pour les mesures RTT.
Pour la famille de détection présentée dans la section~\ref{sec:cpt}, deux principaux paramètres doivent être définis: la pénalité et la fonction distribution des coûts (qui depend de l'hypothèse de la distribution).
Nous considérons la combinaison entre tous les critères d'information introduits (AIC, BIC, MBIC et Hannan-Quinn), 
et tous les types de distribution supportés (Gaussiane, Poisson, Exponentiel et Gamma), y compris l'approche non-paramétrique basée sur la distribution empirique.

Avec quelques tests préliminaires, nous avons rapidement réalisé que la détection avec la distribution normale tend à être sur-sensible, 
sous tous les configuration possibles de pénalité.
Beaucoup de bruits de vie courts et insignifiants sont marqués comme des changements.
C'est parce que la moyenne et la variance de la distribution normale sont indépendamment contrôlées par deux paramètres distincts, ce qui augmente les chances de s'adapter à des changements subtils de niveau ou de volatilité.
D'un autre côté, les distributions exponentielle, Gamma et de Poisson sont trop engourdies.
La moyenne et la variance de Poisson et de la distribution exponentielle sont couplées par un paramètre,
qui restreint leur liberté d'ajustement~\footnote{Poisson, mean = variance = $\lambda$; exponentielle, moyenne / variance = $\lambda$, moyenne = $1/\lambda$.}.
La distribution gamma est confrontée au même problème, mais avec une histoire plus compliquée.
Une distribution gamma peut être décrite par deux paramètres $\alpha$ et $\beta$: mean = $\frac{\alpha}{\beta}$, variance = $\frac{mean}{\beta}$.
\cite{Killick2013a}, l'implémentation que nous utilisons, nécessite une entrée \textit{a priori} pour $\alpha$, qui détermine en fait la sensibilité globale.
Seul $\beta$ est ajusté pour la détection de changement.
Avec un plus grand $\alpha$, un $\beta$ plus grand est nécessaire pour maintenir la même estimation moyenne pour un segment donné.
Une moyenne fixe avec un plus grand $\beta$ impose une plus petite tolérance de variation, donc plus susceptible de diviser le segment donné en raison de changements de variance plus petits.
En bref, un plus grand $\alpha$ conduit à une détection plus sensible.
L'option par défaut définit $\alpha$ à 1, ce qui dégénère la distribution Gamma en distribution exponentielle.
Nous avons également essayé $\alpha$ de 1 à 100, avec l'étape égale à 1.
Aucun d'entre eux ne surpasse les meilleurs paramètres affichés plus tard.
Nous ne considérons donc plus la distribution Gamma.

En supposant une distribution exponentielle et de Poisson, 
nous remarquons que le niveau moyen d'une série temporelles de RTT dicte d'une certaine manière la tolérance de variation.
Par exemple, pour un chemin incluant des liaisons transpacifiques, nous nous attendons à un RTT minimum supérieur à $80msec$.
Dans ce cas, la distribution de Poisson correspondante pourrait facilement tolérer plusieurs déviations RTT de $20msec$, ce qui est déjà non négligeable.
Cependant, le fait d'avoir une moyenne et une variance couplées peut aussi être une caractéristique désirée.
Nous avons observé au cours de l'étiquetage que le niveau d'un segment RTT et sa variance sont souvent positivement liés au cours des périodes de congestion.

Pour tirer parti de la caractéristique décrite ci-dessus et augmenter la sensibilité de détection, nous proposons pour la distribution exponentielle et de Poisson une \textit{transformation de données}: 
soustraire la série temporelle de RTT par sa valeur minimum (baseline) pour abaisser son niveau global.
Les changements sont ensuite détectées pour la série temporelle RTT supprimée en base lorsque l'on suppose une distribution de Poisson et exponentielle.
Ce paramètre est noté \texttt{cpt\_poisson} et \texttt{cpt\_exp} respectivement.
Par souci de comparaison, nous considérons également la distribution de Poisson \textbf{sans transformation de données} 
et nous l'indiquons comme \texttt{cpt\_poisson\_naive}.
La distribution normale et l'approche non-paramétrique sont appliquées directement sur les mesures RTT initiales.

Toutes les combinaisons entre les types de distribution et les choix de pénalité sont utilisées pour détecter les changements dans l'ensemble de données de vérité au sol.
Pour chaque type de distribution, nous plaçons seulement son paramètre de pénalité le plus performant en termes de score $F_2$ pondéré dans la figure~\ref {fig_eval_eval}.

Plus de $ 75\%$ de changements, en termes de poids, peuvent être détectés pour plus de la moitié des séries temporelles avec l'une de ces distributions.
Tous ces types de distribution ont une meilleure pondération $F_2$ que le classique $F_2$, indiquant que certains changement non-détectés sont en effet de peu d'importance opérationnelle.
Cependant, il semble avoir un grand espace pour des améliorations.
Des efforts sont particulièrement nécessaires pour augmenter la précision des résultats de la détection.

La précision de \texttt{cpt\_normal} est particulièrement mauvaise.
Cela confirme que \texttt{cpt\_normal} est en effet sur-sensible pour le type de données RTT.
Au contraire, le rappel de \texttt{cpt\_normal} est remarquable parmi tous les candidats.
Cependant, ses scores $F_2$ sont les plus faibles.
La piètre performance globale de la détection souligne l'importance de trouver un juste équilibre entre sensibilité et pertinence.
Il suggère également que la qualité de l'ajustement n'est pas une garantie de performances de détection.
Pour les méthodes restantes, leurs performances sont relativement proches.
Par rapport à \texttt{cpt\_poisson\_naive} (sans transformation de données), 
\texttt{cpt\_poisson} obtient un rappel plus élevé sans sacrifier de façon évidente la précision.
Par conséquent, \texttt{cpt\_poisson} présente un léger avantage sur les performances globales.
En fait, sans transformation de données, en supposant la distribution exponentielle ne détecte aucun changement pour une grande partie des séries temporelles dans l'ensemble de données de vérité terrain.
Ce sont toutes des preuves que la transformation de données proposée améliore les performances de détection pour la distribution de Poisson et exponentielle.

Nous détectons aussi les changements de chemin rencontrés par les mesures RTT collectées.
Les changements de chemin de niveau AS et IP sont pris en compte.
Ils sont connus pour avoir un impact potentiel sur RTT.
Le but de la détection de changement de chemin n'est pas de répéter certaines des études présentées dans la section~\ref{sec:rtt_path},
tel que quel type de changement de chemin contribue le plus au changement RTT.
Cela aide plutôt à améliorer la compréhension de la détection de changements pour les mesures RTT.

Le tableau~\ref{tab:corr_overview} détaille le nombre de correspondances entre les changements de chemin et de RTT.
Chaque cellule indique le nombre de correspondances entre la ligne (type de changement de chemin) et la colonne (méthode de détection de changement RTT).
La dernière colonne contient le nombre total de changements de chemins de chaque type.
De même, la dernière ligne fournit le nombre total de changements RTT détectés par les deux méthodes.

La fraction des changements de chemin d'AS correspondant aux changements de RTT par l'une ou l'autre méthode de détection dans cet étude 
est beaucoup plus faible que le $72.5\%$ dans~\cite{Rimondini2014}.
Il semble que les changements de chemin AS ont un impact moins significatif sur RTT que la compréhension précédente.
Y a-t-il quelque chose de particulier dans notre ensemble de données ou nos méthodes?
De plus, le nombre de changements de chemin d'AS correspondant à un changement de RTT par \texttt{cpt\_np} 
n'est que d'une moitié de celui par \texttt{cpt\_possion}. Pourquoi?
Tous ces phénomènes sont très intrigants.
Nous explorons les raisons sous-jacentes dans la section~\ref{sec:corr}.
Dans ce condensé, nous expliquons uniquement une de ces observations: pourquoi il y a une grande partie de changement RTT correspondent à aucun changements de chemin.

D'abord, nous n'avons pas été en mesure de mesurer le chemin de reoutr avec RIPE Atlas.
Par conséquent, il est impossible de détecter les changements de chemin sur cette partie-là.
Cependant, ces changements de chemin pourraient avoir contribué aux changements de RTT.
Notamment dans le contexte du routage inter-domaines où les chemins dans les deux sens risquent d'être asymétriques.
Cela implique que les changements RTT provoqués par les changements de chemin de retour sont probablement différents de ceux provoqués par les changements de chemin d'aller.

Deuxièmement, la congestion.
La congestion peut être indépendante des changements de chemin et pourtant elle peut causer des variations significatives sur RTT.
La figure~\ref{fig:case_26328} donne un exemple typique de changements RTT probablement causés par la congestion.
Il y a trois augmentations transitoires de RTT qui peuvent être visuellement remarquées dans les séries temporelles RTT illustrées.
Nous disons que les deux derniers sont probablement de la congestion.
Premièrement, ils ne correspondent à aucun changement de chemin, au moins dans la direction aller.
Deuxièmement, ces augmentations sont probablement causées par le remplissage des files d'attente le long du chemin.
Parce que, les RTT ne sont pas ``plates''.
Sur un chemin légèrement chargé, nous nous attendons à des mesures RTT relativement constantes.
C'est parce que les files d'attente sont presque vides, donc pas de place pour la variation de délai.
La valeur de RTT est dominée par la latence de propagation.
D'un autre côté, les variations de RTT à l'intérieur de la bosse est probablement une manifestation de l'évolution de la demande de trafic, et comment il change la longueur des files d'atteinte.
Les deux bosses/congestion s'écartent de la value de base (la latence de propagation) et durent plusieurs heures.
Ils ont donc un impact significatif sur les performances de transmission.
Nous les avons détectés avec succès avec les méthodes de détection de changement étudiés dans cette thèse.
Cependant, une telle détection n'est pas possible avec la méthode précédemment proposée~\cite{Luckie2014}.
Il effectue une analyse spectrale sur les séries temporelles de RTT pour trouver des congestion périodique.
Une telle congestion persistante est normalement due au manque de capacité du réseau.
Pendant ce temps, la congestion transitoire dans la figure~\ref {fig:case_26328} est plus probablement causée par des variations de trafic soudaines.
La TE basé sur la mesure vise à éviter les deux types de congestion lorsqu'il existe des chemins alternatifs avec la capacité disponible.
A cet effet, les méthodes de détection de changement sont utiles pour notifier la présence de telles variations de performance.

Troisièmement, la détection sur-sensible.
Si nous supposons hardiment que les changements de chemin sur les chemins de retour provoquent une quantité comparable de changements de RTT comme le font les changements de chemin d'aller, il y a encore de nombreux changements de RTT non appariés.
Certains d'entre eux pourraient être effectivement attribués à la congestion, comme expliqué ci-dessus.
Les modifications RTT non appariées restantes sont manifestement le résultat d'une détection trop sensible.
Nous relevons à partir d'une vue macroscopique, dans la section~\ref{sec:cpt_trace} et la section~\ref {sec:as_match_diff}, 
que \texttt{cpt\_poisson} a tendance à surestimer le nombre de changement lorsque la série temporelle de RTT est bruyante.
Alors, \texttt{cpt\_np} est capable de détecter les changements délicats.
Des exemples individuels sont données dans la figure~\ref{fig:case_sensitivity} pour illustrer 
la nuance de sensibilité à partir d'une vue microscopique.
Dans la figure~\ref{fig:case_28002}, \texttt{cpt\_np} a détecté toute la congestion périodique de petite amplitude.
C'est en fait assez impressionnant, car ces changements sont à peine visibles pour les experts humains.
Les changements marqués par \texttt{cpt\_np} ont en effet mis en évidence leur présence, et les ont rendus plus faciles à remarquer visuellement.
Dans la figure~\ref{fig:case_26328}, les deux méthodes ont identifié les deux grandes bosses près de la fin de la série temporelle.
La différence est que\texttt{cpt\_poisson} a également marqué les changements de niveau intermédiaire.
Ces changement intermédiaires ne sont pas corrélés aux changements de chemin.
En plus de cela, ils sont également redondants en informant la congestion qui se produisait à ce moment-là.
La raison d'une telle sur-sensibilité était due à son incompétence dans l'ajustement de la sensibilité de détection en fonction du niveau de variance d'entrée. 
Ce problème est exploré et expliqué dans la section~\ref{sec:over_sensitive}.

Pour résumer le travail de cette section, nous avons proposé un cadre d'évaluation pour la détection des changements sur les séries temporelles RTT.
Le cadre est robuste avec l'ensemble de données étiqueté manuellement et pondère les changements RTT en fonction de leur importance dans le fonctionnement du réseau.
Nous avons en outre conçu une transformation de données adaptée aux mesures RTT pour améliorer la sensibilité de détection de certaines méthodes de détection.
En détectant les changements de chemin, nous distinguons ceux causés par les changements de routage de ceux dus à l'équilibrage de charge.
Enfin, nous corrélons les changements RTT et path détectés en établissant une correspondance entre eux.
Nous avons étudié la distinction de sensibilité entre différentes méthodes de détection des changements.

\section*{Déduire l'emplacement responsable de changements RTT}
Cette idée a d'abord été inspirée par l'étude de cas dans la section~\ref{sec:ripe_case_study} sur les changements RTT partagés par plusieurs séries temporelles RTT provenant de différents AS.
Nous avons réalisé que ces changements RTT ne sont pas exclusifs aux mesures sur un chemin Internet spécifique, 
mais impactent plutôt plusieurs séries temporelles RTT simultanément, comme le montre la figure~\ref {fig:rtt3d_mp_cls2}.
Optimiser le routage interdomaine contre la cause de tels changements de RTT serait alors une approche plus fondamentale et plus efficace de TE que de traiter chaque préfixe individuel et chaque chemin vers eux.

Afin de déduire l'emplacement des causes, une hypothèse raisonnable est que de tels changements RTT partagés sont plus probablement causés par les parties communes de ces chemins, 
au lieu d'être la conséquence de la synchronisation parfaite de plusieurs problèmes dispersés dans divers endroits.
Avec cela, il est alors possible d'affiner la portée des causes possibles avec des mesures ayant à la fois des parties communes et des parties divergentes.
Un exemple de jeu d'inférence est donné dans la figure~\ref{fig:chap5_toy_inference}.
Avec l'hypothèse, nous pouvons d'abord étendre la cause aux liens 1 et 4, aux nœuds 2 et 5.
Comme il y a une mesure sans changement de RTT, celui traversant lien 1 et le nœud 2.
lien 1 et le nœud 2 sont ainsi moins probable d'être la cause.
En consequence, le lien 4 et le nœud 5 sont alors plus susceptibles d'être la cause.
%Dans la section~\ref{sec:inference}, nous décrirons plus formellement les hypothèses et la logique d'inférence pour l'investigation des nœuds et des liens sous tous les modèles de topologie et distributions de mesures possibles.

Nous sommes intéressés à identifier la partie de l'Internet, aussi précise que possible, qui est responsable des changements RTT détectés.
Ceux que nous avons en entrée sur la plates-formes TE chez les clients sont 1) les mesures RTT provenant de sources multiples vers des destinations multiples pour les utilisations TE; 
2) les chemins AS sous-jacents pour ces mesures RTT.
Les sources de mesures sont les plates-formes clientes et les destinations sont les préfixes auxquels les clients envoient du trafic.
La source des mesures peut être multiple si nous fusionnons des mesures à partir de plusieurs plates-formes clientes ou si le client a plusieurs sites avec différentes options de fournisseur.

La figure~\ref{fig:chap5_sys_design} décrit les blocs de fonction pour l'inférence du changement de RTT. 
La détection de changement (section~\ref {sec:cpt_rtt}) transforme les séries temporelles de RTT en séquences d'evènement de change.
La construction de la topologie construit un graph pour les AS et les liaisons traversés par les mesures RTT.
Ce graphe de topologie est une étape intermédiaire dans la conception d'une métrique d'inférence pour chaque nœud et chaque lien présents dans la topologie. 
Comme on le voit sur la figure~\ref {fig:chap5_toy_inference}, si un nœud/lien est la cause du changement RTT, 
dépend non seulement des mesures qui le traversent, mais aussi de celles à coté. 
L'identification de tels ensembles de mesures pour chaque nœud/lien nécessite des connaissances sur la topologie. 
De plus, le graphe de topologie sert aussi à visualiser l'emplacement des changements RTT.
La valeur exacte de ces métriques d'inférence à chaque instant est calculée à partir de séquences d'événements de changement RTT. 
Ensuite, l'inférence de cause est effectuée pour chaque nœud et chaque lien en fonction de la valeur de leurs métriques d'inférence.
% Les séquences d'événements de modification RTT instancient les métriques d'inférence sur lesquelles l'inférence de cause est effectuée.
La sortie de l'ensemble du système indique les liens et les noeuds responsables des changements RTT à un moment donné.

Afin d'initier l'inférence, nous avons fait deux hypothèses.
\begin{assumption}{1}{cause unique}
Pour chaque changement RTT détecté, il n'y a qu'une seule cause, nœud ou lien, sur le chemin mesuré.
\end{assumption}
C'est une hypothèse courante faite dans les études de congestion de TCP~\cite{mathis1997macroscopic, Cardwell2016}. 
S'il y a une congest le long du chemin, il se stabilisera finalement sur le lien avec la bande passante la plus faible.
Nous étendons cette hypothèse aux liens inter-AS et AS pour s'adapter à la granularité d'inférence.

\begin{assumption}{2}{parties communes}
Si les mesures sur plusieurs chemins subissent un changement RTT partagé, les parties communes de ce chemin mesuré sont plus susceptibles d'être la cause.
\end{assumption}
Il décrit une façon possible de satisfaire l'hypothèse précédente lorsque plusieurs mesures RTT avec des intersections sur leur chemins sont considérées.
C'est simplement un cas plus probable que d'avoir simultanément plusieurs parties éloignées dans l'Internet provoquent un changement significatif à la même instant. 
Nous utilisons cette hypothèse pour concevoir des ensembles de mesures spécifiques (métrique d'inférence) pour chaque nœud et chaque lien dans les graph de topologie.
Ensuit, nous examinons leur responsabilité de changement RTT à chaque intervalle de temps de 10 minutes.

Pour vérifier si un nœud (AS) $n$ est la cause exclusive d'un changement RTT partagées, nous
concevoir pour elle des ensembles de mesures (métrique d'inférence), dans lesquels le seul élément commun est le nœud lui-même. 
Si une majorité des mesures dans un tel ensemble expérimentent en même temps un changement de RTT, nous pouvons alors le localiser au nœud à l'étude, selon l'hypothèse~\ref{as:1}.

Après inférence de cause pour chaque nœud, nous pouvons exclure tous les liens avec l'un de ses deux nœuds inférés comme cause, selon l'hypothèse~\ref{as:2}.
Ensuite, si un lien provoque effectivement un changement de RTT, nous nous attendons à ce qu'une majorité de mesures traversant ce lien subissent simultanément (dans un même intervalle de temps) un changement de RTT, 
condition nécessaire mais non suffisante pour la responsabilité de lien. 
En d'autres termes, en violant cette condition, le lien peut être exempté d'être cause du changement RTT.

Pour les liens restantes, leur responsabilité dépend des liens adjacents et non adjacents. 
Imaginez qu'un incident se produise au cœur d'Internet ou à un grand IXP, un large éventail de mesures traversant des liens périphériques, depuis la prochaine cause jusqu'à la bordure de l'Internet, peut être potentiellement impacté. 
Pourtant, ces liens périphériques ne sont pas responsables du changement RTT.
Pour retracer la véritable cause du changement, différents critères sont nécessaires pour les liens dans différentes configurations topologiques.

Nous avons implémenté un outil de visualisation interactif pour inspecter le nombre normalisé d'événements de changement RTT 
et le résultat d'inférence de chaque lien sur la topologie au niveau AS.
La figure~\ref{fig:case_event_count} est un capture d'écran de l'outil qui montre l'intensité de changement RTT sur chaque lien.

\section*{Conclusion}

Cette thèse est développée autour d'une poursuite de 
\textit{mieux utiliser les diverses mesures de réseau dans l'ingénierie du trafic sortant en interdomaine pour les AS stub}.

Nous avons souligné la nécessité de se concentrer sur les destinations les plus importantes.
Grâce à l'étude du dynamisme temporel des volumes par préfixe,
nous sommes arrivés avec des méthodes simples qui sélectionnent efficacement les préfixes de destination avec des volumes de trafic importants.
La scalabilité du système de mesure peut ainsi être améliorée, sans sacrifier beaucoup la couverture de trafic.

Plus tard, nous nous sommes concentrés sur les mesures de latence.
Nous avons présenté et diagnostiqué certains problèmes de qualité des données.
Des lignes directrices pour atténuer leurs impacts sur le traitement des données et la sélection des routes ont été discutées.

Afin de mieux interpréter les mesures de performance, nous avons introduit l'analyse de changement dans le traitement des séries temporelles RTT.
Ces méthodes détectent des changements significatifs dans la performance du chemin et servent de déclencheur pour la resélection de route.
Pour permettre et encourager les efforts futurs, nous avons construit un cadre d'évaluation pour la détection de changement sur les mesures RTT dans l'Internet.

Enfin, avec l'aide de l'analyse de changement, nous avons été en mesure de qualifier le pourcentage d'un groupe de mesures qui a subi des changements RTT au même moment.
Nous avons en outre inféré les emplacements dans l'Internet qui ont potentiellement provoqué ces changements.
Cette visibilité permet d'optimiser les chemin pour les préfixes que nous n'avons pas pu mesurer directement.
Afin de mieux illustrer le processus d'inférence et les causes identifiées, 
nous avons conçu des outils de visualisation interactifs pour tracer les métriques d'inférence et les résultats sur un graphe de topologie.

\end{otherlanguage}
\endgroup			

%\vfill
